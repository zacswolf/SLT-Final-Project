{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 import packages\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.data_loader import data_provider\n",
    "import matplotlib.pyplot as plt\n",
    "from models.bi_lstm import bi_LSTM\n",
    "from models.transformer import Transformer\n",
    "from models.bert_inspired import BertInspired\n",
    "from models.ast_models import ASTModel\n",
    "from utils.tools import dotdict\n",
    "from utils.data_loader import DataModule\n",
    "import pytorch_lightning as pl\n",
    "from exp.exp_main import ExpMain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ssast\" # \"bert_inspired\" \"transformer\" or \"biLSTM\"\n",
    "\n",
    "model = None\n",
    "model_config = None\n",
    "if model_type == \"biLSTM\":\n",
    "    # Create model\n",
    "    model_config = dotdict({\n",
    "        \"input_dim\": 128,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"output_dim\": 9,\n",
    "        \"num_layers\": 2,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    # create model\n",
    "    model = bi_LSTM(model_config)\n",
    "    # model.to(device)\n",
    "elif model_type == \"transformer\":\n",
    "    model_config = dotdict({\n",
    "        \"enc_in\": 128,\n",
    "        \"dec_in\": 128,\n",
    "        \"c_out\": 9,\n",
    "        \"d_model\": 128,\n",
    "        \"dropout\": .05,\n",
    "        \"output_attention\": False,\n",
    "        \"n_heads\": 8,\n",
    "        \"d_ff\": None,\n",
    "        \"activation\": \"gelu\",\n",
    "        \"e_layers\": 2,\n",
    "        \"d_layers\": 1,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    model = Transformer(model_config)\n",
    "    # model.to(device)\n",
    "elif model_type == \"bert_inspired\":\n",
    "    model_config = dotdict({\n",
    "        \"enc_in\": (32, 16), # (#windows, # mel filters)\n",
    "        \"c_out\": 9,\n",
    "        \"d_model\": 512,\n",
    "        \"dropout\": .05,\n",
    "        \"output_attention\": False,\n",
    "        \"n_heads\": 8,\n",
    "        \"d_ff\": None,\n",
    "        \"activation\": \"gelu\",\n",
    "        \"e_layers\": 12,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    model = BertInspired(model_config)\n",
    "    # model.to(device)\n",
    "elif model_type == \"ssast\":\n",
    "    model_config = dotdict({\n",
    "        # \"enc_in\": (32, 16), # (#windows, # mel filters)\n",
    "        # \"c_out\": 9,\n",
    "        # \"d_model\": 512,\n",
    "        # \"dropout\": .05,\n",
    "        # \"output_attention\": False,\n",
    "        # \"n_heads\": 8,\n",
    "        # \"d_ff\": None,\n",
    "        # \"activation\": \"gelu\",\n",
    "        # \"e_layers\": 12,\n",
    "        # \"model_type\": model_type\n",
    "        \"label_dim\": 9,\n",
    "        \"fshape\": 16,\n",
    "        \"tshape\": 16,\n",
    "        \"fstride\": 10,\n",
    "        \"tstride\": 10,\n",
    "        \"input_fdim\": 128, # we need data sets with 128 mel filters\n",
    "        \"input_tdim\": 32, # This can change depending on data set\n",
    "        \"model_size\": 'base'\n",
    "    })\n",
    "\n",
    "    # label_dim=527,\n",
    "    # fshape=128, tshape=2, fstride=128, tstride=2,\n",
    "    # input_fdim=128, input_tdim=1024, model_size='base',\n",
    "    # pretrain_stage=True, load_pretrained_mdl_path=None\n",
    "    model = ASTModel(**model_config, pretrain_stage=False, load_pretrained_mdl_path=\"pretrained_mdls/SSAST-Base-Patch-400.pth\")\n",
    "\n",
    "assert model is not None, \"Didn't select a valid model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = dotdict({\n",
    "        \"seq_len\": 9,\n",
    "        \"pred_len\": 3,\n",
    "        \"data_id\": \"16x32\",\n",
    "        \"batch_size\": 512,\n",
    "        \"learning_rate\": 0.000001,\n",
    "        \"max_epochs\": 5,\n",
    "        \"loss\": \"BCE\",\n",
    "        \"num_mel\": 128,\n",
    "        \"num_frames\": 16,\n",
    "        \"segment_duration\": 100\n",
    "    })\n",
    "\n",
    "\n",
    "strategy = \"dp\" # [\"ddp\", \"ddp_spawn\", \"ddp_notebook\", \"ddp_fork\", None]\n",
    "num_workers = os.cpu_count() * (strategy != \"ddp_spawn\")\n",
    "\n",
    "\n",
    "pl.seed_everything(seed=123, workers=True)\n",
    "data_module = DataModule(exp_config, num_workers)\n",
    "\n",
    "\n",
    "# Intantiate Lightning Model\n",
    "exp = ExpMain(model, exp_config)\n",
    "\n",
    "# Create Trainer\n",
    "trainer_params = {\n",
    "    \"max_epochs\":exp_config.max_epochs, \n",
    "    # \"auto_scale_batch_size\": \"power\",\n",
    "    # \"auto_lr_find\": True,\n",
    "    \"logger\": True,\n",
    "    \"accelerator\": \"gpu\", \"devices\": 1, \"auto_select_gpus\": True, \"strategy\": strategy # GPUS\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_params)\n",
    "\n",
    "# Tune model (noop unless auto_scale_batch_size or auto_lr_find)\n",
    "tuner_result = trainer.tune(exp, datamodule=data_module)\n",
    "if \"lr_find\" in tuner_result:\n",
    "    tuner_result[\"lr_find\"].plot(suggest=True)\n",
    "if \"scale_batch_size\" in tuner_result:\n",
    "    print(\"scale_batch_size:\", tuner_result[\"scale_batch_size\"])\n",
    "\n",
    "trainer.logger.log_hyperparams(model_config | exp_config)\n",
    "# Train Model\n",
    "trainer.fit(exp, data_module)\n",
    "\n",
    "# Test Model\n",
    "trainer.test(exp, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "da06df106b6ebc505395780f3c76810614ede012a8d0e2bc265d4156a4243031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
