{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 import packages\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from numba import cuda as numba\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.data_loader import data_provider\n",
    "import matplotlib.pyplot as plt\n",
    "from models.bi_lstm import bi_LSTM\n",
    "from models.transformer import Transformer\n",
    "from models.bert_inspired import BertInspired\n",
    "from utils.tools import dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 GPU stuff\n",
    "device_num = 1\n",
    "device = torch.device(f\"cuda:{device_num}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"torch device: \", torch.cuda.get_device_name(device))\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "# function to clear GPU memory\n",
    "def free_gpu_cache():                        \n",
    "    torch.cuda.empty_cache()\n",
    "    numba.select_device(device_num)\n",
    "    numba.close()\n",
    "    numba.select_device(device_num)\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 helper functions for training\n",
    "\n",
    "def test_network(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            # get data\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            #print (\"labels: \", labels)\n",
    "            #print (\"pred: \", outputs)\n",
    "            total = labels.shape[0] * labels.shape[1]\n",
    "            correct = 0\n",
    "            for i, frame in enumerate(labels):\n",
    "                #print (i, \" frame: \", frame)\n",
    "                #print (i, \" outputs[i]: \", outputs[i])\n",
    "                for val in torch.eq(frame, outputs[i]):\n",
    "                    if val:\n",
    "                        correct += 1\n",
    "            \n",
    "    return 100 * correct / total\n",
    "\n",
    "def print_stats(iteration_list, accuracy_list, loss_list):\n",
    "    # final accuracy plot        \n",
    "    plt.plot(iteration_list, accuracy_list)\n",
    "    plt.title(\"accuracy over time\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.show()\n",
    "    \n",
    "    # final loss plot        \n",
    "    plt.plot(iteration_list, loss_list)\n",
    "    plt.title(\"loss over time\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"bert_inspired\" # \"bert_inspired\" \"transformer\" or \"biLSTM\"\n",
    "\n",
    "model = None\n",
    "if model_type == \"biLSTM\":\n",
    "    # Create model\n",
    "    config = dotdict({\n",
    "        \"input_dim\": 128,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"output_dim\": 9,\n",
    "        \"num_layers\": 2,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    # create model\n",
    "    model = bi_LSTM(config)\n",
    "    model.to(device)\n",
    "elif model_type == \"transformer\":\n",
    "    # 0 = ????\n",
    "    config = dotdict({\n",
    "        \"enc_in\": 128,\n",
    "        \"dec_in\": 128,\n",
    "        \"c_out\": 9,\n",
    "        \"d_model\": 128,\n",
    "        \"dropout\": .05,\n",
    "        \"output_attention\": False,\n",
    "        \"n_heads\": 8,\n",
    "        \"d_ff\": None,\n",
    "        \"activation\": \"gelu\",\n",
    "        \"e_layers\": 2,\n",
    "        \"d_layers\": 1,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    model = Transformer(config)\n",
    "    model.to(device)\n",
    "elif model_type == \"bert_inspired\":\n",
    "    config = dotdict({\n",
    "        \"enc_in\": (32, 16), # (#windows, # mel filters)\n",
    "        \"c_out\": 9,\n",
    "        \"d_model\": 512,\n",
    "        \"dropout\": .05,\n",
    "        \"output_attention\": False,\n",
    "        \"n_heads\": 8,\n",
    "        \"d_ff\": None,\n",
    "        \"activation\": \"gelu\",\n",
    "        \"e_layers\": 12,\n",
    "        \"model_type\": model_type\n",
    "    })\n",
    "    model = BertInspired(config)\n",
    "    model.to(device)\n",
    "\n",
    "assert model is not None, \"Didn't select a valid model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 Training\n",
    "\n",
    "# free_gpu_cache()\n",
    "\n",
    "# training parameters\n",
    "batch_size = 512\n",
    "learning_rate = 0.0000001\n",
    "num_epochs = 5\n",
    "\n",
    "# get dataloaders\n",
    "# train_dataset, train_loader, test_dataset, test_loader, val_dataset, val_loader  = set_up_dataloaders(\n",
    "#     batch_size, load_datasets(data_id=\"_5s_50hz\", print_out=True)\n",
    "# )\n",
    "\n",
    "config = dotdict({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_workers\": 0,\n",
    "        \"seq_len\": 9,\n",
    "        \"data_id\": \"32x16\"\n",
    "    })\n",
    "\n",
    "train_dataset, train_loader = data_provider(config, flag=\"train\")\n",
    "val_dataset, val_loader = data_provider(config, flag=\"val\")\n",
    "test_dataset, test_loader = data_provider(config, flag=\"test\")\n",
    "# seq_length x num_windows x num_mel_filters\n",
    "\n",
    "# print (\"device name: \", torch.cuda.get_device_name(0))\n",
    "# print (\"model.type: \", myModel.model_type)\n",
    "# print (\"model.device: \", next(myModel.parameters()).device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# lists for data collection\n",
    "iter = 0\n",
    "delta = 100\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "loss_list = []\n",
    "\n",
    "# Perform epochs\n",
    "startTime = time.time()\n",
    "min_valid_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_loss = 0.0\n",
    "    for batch_index, (feats, labels) in enumerate(tqdm(train_loader)):\n",
    "        feats = feats.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        output = model(feats)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for batch_index, (feats, labels) in enumerate(tqdm(val_loader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        feats = feats.float().to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        output = model(feats)\n",
    "        loss = criterion(output,labels)\n",
    "        # Calculate Loss\n",
    "        valid_loss += loss.item()\n",
    "    valid_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch}\\t\\tTraining Loss: {train_loss}\\t\\tValidation Loss: {valid_loss}\") \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f\"Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f})\\tSaving The Model\")\n",
    "        min_valid_loss = valid_loss\n",
    "         \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "\n",
    "    \n",
    "    # print(f'\\t iteration: {iter}\\t loss: {loss_list[len(loss_list)-1].item():.3f}\\t accuracy: {accuracy_list[len(accuracy_list)-1]:.3f} %') \n",
    "    # print('Test accuracy: %d %%' % (100 * correct / total)) \n",
    "        # test accuracy and log stats\n",
    "        # if iter % delta == 0 and iter != 0:\n",
    "        #     print(\"Testing Network\")\n",
    "        #     acc = test_network(model, test_loader)\n",
    "        #     iteration_list.append(iter)\n",
    "        #     accuracy_list.append(acc)\n",
    "        #     loss_list.append(loss)\n",
    "        #     print(f'\\t iteration: {iter}\\t loss: {loss_list[len(loss_list)-1].item():.3f}\\t accuracy: {accuracy_list[len(accuracy_list)-1]:.3f} %')\n",
    "    \n",
    "        # # increase iteration\n",
    "        # iter += 1\n",
    "\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "da06df106b6ebc505395780f3c76810614ede012a8d0e2bc265d4156a4243031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
