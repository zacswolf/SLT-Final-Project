{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 import packages\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 load in datasets\n",
    "\n",
    "def load_datasets(data_id, print_out = False, train_device=\"cpu\", val_device=\"cpu\", test_device=\"cpu\"):\n",
    "    # load files\n",
    "    train_feats = np.load(\"data/dataset\" + data_id + \"/train_feats\" + data_id + \".npy\", allow_pickle=True)\n",
    "    train_labels = np.load(\"data/dataset\" + data_id + \"/train_labels\" + data_id + \".npy\", allow_pickle=True)\n",
    "    test_feats = np.load(\"data/dataset\" + data_id + \"/test_feats\" + data_id + \".npy\", allow_pickle=True)\n",
    "    test_labels = np.load(\"data/dataset\" + data_id + \"/test_labels\" + data_id + \".npy\", allow_pickle=True)\n",
    "    val_feats = np.load(\"data/dataset\" + data_id + \"/val_feats\" + data_id + \".npy\", allow_pickle=True)\n",
    "    val_labels = np.load(\"data/dataset\" + data_id + \"/val_labels\" + data_id + \".npy\", allow_pickle=True)\n",
    "    # reshape numpy arrays\n",
    "    train_feats = train_feats.reshape(train_feats.shape[0]*train_feats.shape[1], train_feats.shape[2])\n",
    "    train_labels = train_labels.reshape(train_labels.shape[0]*train_labels.shape[1], train_labels.shape[2])\n",
    "    test_feats = test_feats.reshape(test_feats.shape[0]*test_feats.shape[1], test_feats.shape[2])\n",
    "    test_labels = test_labels.reshape(test_labels.shape[0]*test_labels.shape[1], test_labels.shape[2])\n",
    "    val_feats = val_feats.reshape(val_feats.shape[0]*val_feats.shape[1], val_feats.shape[2])\n",
    "    val_labels = val_labels.reshape(val_labels.shape[0]*val_labels.shape[1], val_labels.shape[2])\n",
    "    \n",
    "    if print_out:\n",
    "        print(\"train feats: \", train_feats.shape, \" type: \", type(train_feats))\n",
    "        print(\"train labels: \", train_labels.shape, \" type: \", type(train_labels))\n",
    "\n",
    "        print(\"test feats: \", test_feats.shape, \" type: \", type(test_feats))\n",
    "        print(\"test labels: \", test_labels.shape, \" type: \", type(test_labels))\n",
    "\n",
    "        print(\"val feats: \", val_feats.shape, \" type: \", type(val_feats))\n",
    "        print(\"val labels: \", val_labels.shape, \" type: \", type(val_labels))\n",
    "\n",
    "    # create tensors\n",
    "    train_feats_tensor = torch.tensor(train_feats, requires_grad=True, dtype=torch.float).to(train_device)\n",
    "    train_labels_tensor = torch.tensor(train_labels, dtype=torch.float).to(train_device)\n",
    "\n",
    "    test_feats_tensor = torch.tensor(test_feats, requires_grad=True, dtype=torch.float).to(test_device)\n",
    "    test_labels_tensor = torch.tensor(test_labels, dtype=torch.float).to(test_device)\n",
    "\n",
    "    val_feats_tensor = torch.tensor(val_feats, requires_grad=True, dtype=torch.float).to(val_device)\n",
    "    val_labels_tensor = torch.tensor(val_labels, dtype=torch.float).to(val_device)\n",
    "\n",
    "    if print_out:\n",
    "        print (\"train feats tensor: \", train_feats_tensor.shape, \" type: \", type(train_feats_tensor))\n",
    "        print (\"train labels tensor: \", train_labels_tensor.shape, \" type: \", type(train_labels_tensor))\n",
    "\n",
    "        print (\"test feats tensor: \", test_feats_tensor.shape, \" type: \", type(test_feats_tensor))\n",
    "        print (\"test labels tensor: \", test_labels_tensor.shape, \" type: \", type(test_labels_tensor))\n",
    "\n",
    "        print (\"val feats tensor: \", val_feats_tensor.shape, \" type: \", type(val_feats_tensor))\n",
    "        print (\"val labels tensor: \", val_labels_tensor.shape, \" type: \", type(val_labels_tensor))\n",
    "            \n",
    "        if print_out:\n",
    "            print (\"train_feats_tensor.device:\", train_feats_tensor.get_device())\n",
    "            print (\"train_labels_tensor.device:\", train_labels_tensor.get_device())\n",
    "            print (\"test_feats_tensor.device:\", test_feats_tensor.get_device())\n",
    "            print (\"test_labels_tensor.device:\", test_labels_tensor.get_device())\n",
    "            print (\"val_feats_tensor.device:\", val_feats_tensor.get_device())\n",
    "            print (\"val_labels_tensor.device:\", val_labels_tensor.get_device())\n",
    "        \n",
    "    return  (train_feats_tensor,\n",
    "            train_labels_tensor,\n",
    "            test_feats_tensor,\n",
    "            test_labels_tensor,\n",
    "            val_feats_tensor,\n",
    "            val_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 set up the data loaders\n",
    "\n",
    "# tensor tuple shape: output of load_datasets()\n",
    "#   [ train_feats_tensor, train_labels_tensor,\n",
    "#     test_feats_tensor, test_labels_tensor,\n",
    "#     val_feats_tensor, val_labels_tensor ]\n",
    "def set_up_dataloaders(batch_size, tensor_tuple):\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(tensor_tuple[0], tensor_tuple[1])\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(tensor_tuple[2], tensor_tuple[3])\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle = False)\n",
    "\n",
    "    val_dataset = torch.utils.data.TensorDataset(tensor_tuple[4], tensor_tuple[5])\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle = False)\n",
    "    \n",
    "    return  (train_dataset, train_loader,\n",
    "            test_dataset, test_loader,\n",
    "            val_dataset, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(my_model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = my_model(128, 9, 32, 2)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "    pass\n",
    "\n",
    "def test_model(model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  # A. For each epoch, do the following:\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    # 1 - For each batch of the epoch, \n",
    "    for batch in dataset:\n",
    "      # 1.a - run the custom \"train_step\" function\n",
    "      # we just declared above\n",
    "      train_step(batch)\n",
    "\n",
    "    # 4 - Print out the completed epoch no. and the time spent\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feats:  (22250, 128)  type:  <class 'numpy.ndarray'>\n",
      "train labels:  (22250, 9)  type:  <class 'numpy.ndarray'>\n",
      "test feats:  (230250, 128)  type:  <class 'numpy.ndarray'>\n",
      "test labels:  (230250, 9)  type:  <class 'numpy.ndarray'>\n",
      "val feats:  (237000, 128)  type:  <class 'numpy.ndarray'>\n",
      "val labels:  (237000, 9)  type:  <class 'numpy.ndarray'>\n",
      "train feats tensor:  torch.Size([22250, 128])  type:  <class 'torch.Tensor'>\n",
      "train labels tensor:  torch.Size([22250, 9])  type:  <class 'torch.Tensor'>\n",
      "test feats tensor:  torch.Size([230250, 128])  type:  <class 'torch.Tensor'>\n",
      "test labels tensor:  torch.Size([230250, 9])  type:  <class 'torch.Tensor'>\n",
      "val feats tensor:  torch.Size([237000, 128])  type:  <class 'torch.Tensor'>\n",
      "val labels tensor:  torch.Size([237000, 9])  type:  <class 'torch.Tensor'>\n",
      "train_feats_tensor.device: -1\n",
      "train_labels_tensor.device: -1\n",
      "test_feats_tensor.device: -1\n",
      "test_labels_tensor.device: -1\n",
      "val_feats_tensor.device: -1\n",
      "val_labels_tensor.device: -1\n"
     ]
    }
   ],
   "source": [
    "# 4.0 model training\n",
    "\n",
    "# training parameters\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "# get dataloaders\n",
    "train_dataset, train_loader, test_dataset, test_loader, val_dataset, val_loader  = set_up_dataloaders(\n",
    "    batch_size, load_datasets(data_id=\"_5s_50hz\", print_out=True)\n",
    ")\n",
    "\n",
    "train(train_dataset, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2eb717040054f9e1cd6390da57b4c3f6de62338193843f816e8f12a4d5407ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
