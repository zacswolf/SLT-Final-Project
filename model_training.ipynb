{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Dense, Dropout, LSTM, Conv2D, Flatten, Bidirectional, MaxPool3D, Reshape)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_midi(np_array):\n",
    "    np_array = np_array.reshape(np_array.shape[0]*np_array.shape[1], np_array.shape[2])\n",
    "    midi_array = np.flip(np_array.T, axis=0)\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(20)\n",
    "    f.set_figheight(10)\n",
    "    plt.imshow(midi_array, cmap='binary', interpolation='None', aspect=\"auto\")\n",
    "    plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "import GPUtil\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# print out system information\n",
    "print ('system version: ', sys.version)\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print('available devices: ', get_available_devices()) \n",
    "\n",
    "# set gpu as device\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "# allow gpu growth\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "# get gpu info\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "def my_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  # model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  # model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  # model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  # model.add(Dropout(0.4))\n",
    "  \n",
    "  model.add(Reshape((28, 128)))\n",
    "  \n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh', return_sequences=True)))\n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh', return_sequences=True)))\n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh')))  \n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(9, activation='sigmoid', name='output'))\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1\n",
    "  \n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost.\n",
    "    Average (1 - soft-F1) across all labels.\n",
    "    Use probability values instead of binary predictions.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    \n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 1, 63, 15, 128)    640       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 1, 62, 14, 128)    65664     \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 1, 31, 7, 128)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 31, 7, 128)     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 1, 30, 6, 128)     65664     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 29, 5, 128)     65664     \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 1, 14, 2, 128)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 14, 2, 128)     0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 28, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 28, 100)          71600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 28, 100)          60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 100)              60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390,941\n",
      "Trainable params: 390,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create new model\n",
    "LR = 0.000001\n",
    "INPUT_SHAPE = (None, 1, 64, 16, 1)\n",
    "\n",
    "model = my_model()\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=tf.losses.binary_crossentropy,\n",
    "  metrics=[macro_soft_f1],\n",
    ")\n",
    "\n",
    "model.build(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings for our own training (9)\n",
    "KICK = 0\n",
    "SNARE = 1\n",
    "HH_CLOSED = 2\n",
    "HH_OPEN = 3\n",
    "RIDE = 4\n",
    "TOM_1 = 5\n",
    "TOM_2 = 6\n",
    "TOM_3 = 7\n",
    "CRASH = 8\n",
    "NUM_FEATS = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and reshape for training\n",
    "DATA_ID = '_64mel_16frames_50ms'\n",
    "\n",
    "train_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"train_feats.npy\"\n",
    "train_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"train_labels.npy\"\n",
    "\n",
    "test_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"test_feats.npy\"\n",
    "test_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"test_labels.npy\"\n",
    "\n",
    "val_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"val_feats.npy\"\n",
    "val_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"val_labels.npy\"\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    # load in data\n",
    "    train_feats_npy = np.load(train_feats_path, allow_pickle=True)\n",
    "    train_labels_npy = np.load(train_labels_path, allow_pickle=True)\n",
    "    \n",
    "    test_feats_npy = np.load(test_feats_path, allow_pickle=True)\n",
    "    test_labels_npy = np.load(test_labels_path, allow_pickle=True)\n",
    "    \n",
    "    val_feats_npy = np.load(val_feats_path, allow_pickle=True)\n",
    "    val_labels_npy = np.load(val_labels_path, allow_pickle=True)\n",
    "    \n",
    "    print ('train feats.shape: ', train_feats_npy.shape)\n",
    "    print ('train labels.shape: ', train_labels_npy.shape)\n",
    "    \n",
    "    print ('test feats.shape: ', test_feats_npy.shape)\n",
    "    print ('test labels.shape: ', test_labels_npy.shape)\n",
    "    \n",
    "    print ('val feats.shape: ', val_feats_npy.shape)\n",
    "    print ('val labels.shape: ', val_labels_npy.shape)\n",
    "\n",
    "    train_feats_npy = train_feats_npy.reshape(train_feats_npy.shape[0], 1, train_feats_npy.shape[1], train_feats_npy.shape[2], 1)\n",
    "    test_feats_npy = test_feats_npy.reshape(test_feats_npy.shape[0], 1, test_feats_npy.shape[1], test_feats_npy.shape[2], 1)\n",
    "    val_feats_npy = val_feats_npy.reshape(val_feats_npy.shape[0], 1, val_feats_npy.shape[1], val_feats_npy.shape[2], 1)\n",
    "\n",
    "    print ('train feats.shape: ', train_feats_npy.shape)\n",
    "    print ('train labels.shape: ', train_labels_npy.shape)\n",
    "    \n",
    "    print ('test feats.shape: ', test_feats_npy.shape)\n",
    "    print ('test labels.shape: ', test_labels_npy.shape)\n",
    "    \n",
    "    print ('val feats.shape: ', val_feats_npy.shape)\n",
    "    print ('val labels.shape: ', val_labels_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network!\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Define some callbacks to improve training.\n",
    "#early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model.fit(\n",
    "        x=train_feats_npy, \n",
    "        y=train_labels_npy, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        validation_data=(val_feats_npy, val_labels_npy), \n",
    "        callbacks=[reduce_lr]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(train_feats_npy, train_labels_npy, batch_size=BATCH_SIZE)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "MODEL_ID = 'model_64mel_16frames_0.05sec_1batch_1epochs'\n",
    "model.save('models/' + MODEL_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9d4ae5fd18cb6e0de1c1eb4db069b31104280bf1d614fdd82a44e1260f58cd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
