{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (Dense, Dropout, LSTM, Conv2D, Flatten, Bidirectional, MaxPool3D, Reshape)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_midi(np_array):\n",
    "    np_array = np_array.reshape(np_array.shape[0]*np_array.shape[1], np_array.shape[2])\n",
    "    midi_array = np.flip(np_array.T, axis=0)\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(20)\n",
    "    f.set_figheight(10)\n",
    "    plt.imshow(midi_array, cmap='binary', interpolation='None', aspect=\"auto\")\n",
    "    plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system version:  3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]\n",
      "tensorflow version:  2.10.1\n",
      "available devices:  ['/device:CPU:0', '/device:GPU:0']\n",
      "Num GPUs Available:  1\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  6% | 23% |\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "import GPUtil\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# print out system information\n",
    "print ('system version: ', sys.version)\n",
    "print('tensorflow version: ', tf.__version__)\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "print('available devices: ', get_available_devices()) \n",
    "\n",
    "# set gpu as device\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "# allow gpu growth\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "# get gpu info\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "def my_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  \n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  model.add(Dropout(0.4))\n",
    "  \n",
    "  # model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  # model.add(Conv2D(filters=128, kernel_size=(2,2), strides=(1,1)))\n",
    "  # model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "  # model.add(Dropout(0.4))\n",
    "  \n",
    "  model.add(Reshape((28, 128)))\n",
    "  \n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh', return_sequences=True)))\n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh', return_sequences=True)))\n",
    "  model.add(Bidirectional(LSTM(units=50, activation='tanh')))  \n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(9, activation='sigmoid', name='output'))\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "        \n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1\n",
    "  \n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost.\n",
    "    Average (1 - soft-F1) across all labels.\n",
    "    Use probability values instead of binary predictions.\n",
    "    \n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix of shape (BATCH_SIZE, N_LABELS)\n",
    "        \n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    \n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "    return macro_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 1, 63, 15, 128)    640       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 62, 14, 128)    65664     \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 1, 31, 7, 128)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 31, 7, 128)     0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 30, 6, 128)     65664     \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 29, 5, 128)     65664     \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 14, 2, 128)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 1, 14, 2, 128)     0         \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 28, 128)           0         \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 28, 100)          71600     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 28, 100)          60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 100)              60400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390,941\n",
      "Trainable params: 390,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create new model\n",
    "LR = 0.000001\n",
    "INPUT_SHAPE = (None, 1, 64, 16, 1)\n",
    "\n",
    "model = my_model()\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "  loss=tf.losses.binary_crossentropy,\n",
    "  metrics=[macro_soft_f1],\n",
    ")\n",
    "\n",
    "model.build(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings for our own training (9)\n",
    "KICK = 0\n",
    "SNARE = 1\n",
    "HH_CLOSED = 2\n",
    "HH_OPEN = 3\n",
    "RIDE = 4\n",
    "TOM_1 = 5\n",
    "TOM_2 = 6\n",
    "TOM_3 = 7\n",
    "CRASH = 8\n",
    "NUM_FEATS = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feats.shape:  (594835, 64, 32)\n",
      "train labels.shape:  (594835, 9)\n",
      "test feats.shape:  (84464, 64, 32)\n",
      "test labels.shape:  (84464, 9)\n",
      "val feats.shape:  (86313, 64, 32)\n",
      "val labels.shape:  (86313, 9)\n",
      "train feats.shape:  (594835, 1, 64, 32, 1)\n",
      "train labels.shape:  (594835, 9)\n",
      "test feats.shape:  (84464, 1, 64, 32, 1)\n",
      "test labels.shape:  (84464, 9)\n",
      "val feats.shape:  (86313, 1, 64, 32, 1)\n",
      "val labels.shape:  (86313, 9)\n"
     ]
    }
   ],
   "source": [
    "# load data and reshape for training\n",
    "DATA_ID = '_128mel_16frames_0.1sec'\n",
    "\n",
    "train_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"train_feats\" + DATA_ID + \".npy\"\n",
    "train_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"train_labels\" + DATA_ID + \".npy\"\n",
    "\n",
    "test_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"test_feats\" + DATA_ID + \".npy\"\n",
    "test_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"test_labels\" + DATA_ID + \".npy\"\n",
    "\n",
    "val_feats_path = \"data/dataset\" + DATA_ID + \"/\" + \"val_feats\" + DATA_ID + \".npy\"\n",
    "val_labels_path = \"data/dataset\" + DATA_ID + \"/\" + \"val_labels\" + DATA_ID + \".npy\"\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    # load in data\n",
    "    train_feats_npy = np.load(train_feats_path, allow_pickle=True)\n",
    "    train_labels_npy = np.load(train_labels_path, allow_pickle=True)\n",
    "    \n",
    "    test_feats_npy = np.load(test_feats_path, allow_pickle=True)\n",
    "    test_labels_npy = np.load(test_labels_path, allow_pickle=True)\n",
    "    \n",
    "    val_feats_npy = np.load(val_feats_path, allow_pickle=True)\n",
    "    val_labels_npy = np.load(val_labels_path, allow_pickle=True)\n",
    "    \n",
    "    print ('train feats.shape: ', train_feats_npy.shape)\n",
    "    print ('train labels.shape: ', train_labels_npy.shape)\n",
    "    \n",
    "    print ('test feats.shape: ', test_feats_npy.shape)\n",
    "    print ('test labels.shape: ', test_labels_npy.shape)\n",
    "    \n",
    "    print ('val feats.shape: ', val_feats_npy.shape)\n",
    "    print ('val labels.shape: ', val_labels_npy.shape)\n",
    "\n",
    "    train_feats_npy = train_feats_npy.reshape(train_feats_npy.shape[0], 1, train_feats_npy.shape[1], train_feats_npy.shape[2], 1)\n",
    "    test_feats_npy = test_feats_npy.reshape(test_feats_npy.shape[0], 1, test_feats_npy.shape[1], test_feats_npy.shape[2], 1)\n",
    "    val_feats_npy = val_feats_npy.reshape(val_feats_npy.shape[0], 1, val_feats_npy.shape[1], val_feats_npy.shape[2], 1)\n",
    "\n",
    "    print ('train feats.shape: ', train_feats_npy.shape)\n",
    "    print ('train labels.shape: ', train_labels_npy.shape)\n",
    "    \n",
    "    print ('test feats.shape: ', test_feats_npy.shape)\n",
    "    print ('test labels.shape: ', test_labels_npy.shape)\n",
    "    \n",
    "    print ('val feats.shape: ', val_feats_npy.shape)\n",
    "    print ('val labels.shape: ', val_labels_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594835/594835 [==============================] - 15587s 26ms/step - loss: 0.1581 - macro_soft_f1: 0.9904 - val_loss: 0.1520 - val_macro_soft_f1: 0.9893 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# train the network!\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# Define some callbacks to improve training.\n",
    "#early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(\n",
    "        x=train_feats_npy, \n",
    "        y=train_labels_npy, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        validation_data=(val_feats_npy, val_labels_npy), \n",
    "        callbacks=[reduce_lr]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(train_feats_npy, train_labels_npy, batch_size=BATCH_SIZE)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_19_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_64mel_16frames_0.05sec_1batch_1epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_64mel_16frames_0.05sec_1batch_1epochs\\assets\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "MODEL_ID = 'model_64mel_16frames_0.05sec_1batch_1epochs'\n",
    "model.save('models/' + MODEL_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2eb717040054f9e1cd6390da57b4c3f6de62338193843f816e8f12a4d5407ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
