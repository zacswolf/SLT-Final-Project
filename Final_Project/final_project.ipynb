{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. import packages\n",
    "\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1.1 GPU stuff\n",
    "\n",
    "# print (\"cuda: \", torch.cuda.is_available())\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print (\"current device: \", device)\n",
    "# print (\"count: \", torch.cuda.device_count())\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print (\"device name: \", torch.cuda.get_device_name(0))\n",
    "#     torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 load groove dataset\n",
    "import math\n",
    "\n",
    "groove_csv = pd.read_csv('groove/info.csv')\n",
    "print(\"groove dataset:\", len(groove_csv))\n",
    "\n",
    "# get train, test, and validation sets\n",
    "train_csv = []\n",
    "test_csv = []\n",
    "validation_csv = []\n",
    "\n",
    "for index, row in groove_csv.iterrows():\n",
    "    if str(row.audio_filename).lower() != \"nan\":\n",
    "        split = row['split']\n",
    "        if split == \"train\":\n",
    "            train_csv.append(row)\n",
    "        elif split == \"test\":\n",
    "            test_csv.append(row)\n",
    "        elif split == \"validation\":\n",
    "            validation_csv.append(row)\n",
    "        \n",
    "print (\"train: \", len(train_csv))\n",
    "print (\"test: \", len(test_csv))\n",
    "print (\"validation: \", len(validation_csv))\n",
    "\n",
    "print (train_csv[0].midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio files into tensors\n",
    "from scipy import signal\n",
    "import audiosegment\n",
    "import librosa\n",
    "import torch\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def audio_to_melspec_tensor(wav_file_path, sample_rate=44_100): \n",
    "    window_size = 0.025\n",
    "    window_stride = 0.01\n",
    "    n_dft = int(sample_rate * window_size)\n",
    "    n_mels = 128\n",
    "    win_length = 1024\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    # load in wav file and remove the mean of the signal\n",
    "    y, sr = librosa.load(wav_file_path, sr=sample_rate)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length, win_length=win_length, window=signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=n_mels, fmin=20)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "    # plot.imshow(logspec.T, origin='lower', aspect='auto')\n",
    "    # plot.show()\n",
    "    # turn into tensor\n",
    "    logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec_tensor\n",
    "\n",
    "def get_feats_and_labels_from_csv(csv_index):\n",
    "    # load in wav file\n",
    "    audio_file_path = \"groove/\" + csv_index.audio_filename\n",
    "    wav_file = audiosegment.from_file(audio_file_path)\n",
    "    # convert sample width if not set to 2 (16 bits)\n",
    "    if wav_file.sample_width != 2:\n",
    "        wav_file = wav_file.set_sample_width(2)\n",
    "        # print(\"\\tnew sample_width: \", wav_file.sample_width)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # convert file from stereo to mono if channels > 1\n",
    "    if wav_file.channels != 1:\n",
    "        wav_file = wav_file.set_channels(1)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # cutting and padding\n",
    "    predefined_length = 12\n",
    "    diced_wav_files = wav_file.dice(predefined_length, zero_pad=True)\n",
    "    # get feature tensors\n",
    "    default_sample_rate = 44100\n",
    "    target_len = predefined_length * default_sample_rate\n",
    "    feats_tensors_list = []\n",
    "    i = 0\n",
    "    for diced_file in diced_wav_files:\n",
    "        # pad with zeros if not correct length\n",
    "        diced_file_len = len(diced_file.to_numpy_array())\n",
    "        if diced_file_len != target_len:\n",
    "            zeros = target_len - diced_file_len\n",
    "            diced_array = np.pad(diced_file.to_numpy_array(), (0, zeros))\n",
    "            diced_file = audiosegment.from_numpy_array(diced_array, framerate=default_sample_rate)\n",
    "        # export temp wav file and convert to tensor\n",
    "        diced_file_path = str(csv_index.id) + \"-\" + str(i) + \".wav\"\n",
    "        diced_file_path = diced_file_path.replace('/', '-')\n",
    "        diced_file_path = \"temp/\" + diced_file_path\n",
    "        diced_file.export(diced_file_path, format=\"wav\")\n",
    "        feats_tensor = audio_to_melspec_tensor(diced_file_path, wav_file.frame_rate)\n",
    "        feats_tensors_list.append(feats_tensor)\n",
    "        i += 1\n",
    "    # get midi file\n",
    "    midi_file = csv_index.midi_filename\n",
    "    # return tensors\n",
    "    return feats_tensors_list #, label_tensor\n",
    "\n",
    "# reset temp folder\n",
    "if os.path.isfile('temp/'):\n",
    "    shutil.rmtree('temp/', ignore_errors=True)\n",
    "    os.mkdir('temp/')\n",
    "\n",
    "i = 0\n",
    "for index in train_csv:\n",
    "    feats_tensors = get_feats_and_labels_from_csv(index) # , label_tensor\n",
    "    for tensor in feats_tensors:\n",
    "        print (i, \"\\ttensor: \", tensor.shape)\n",
    "\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4872d8d3c2bbc685ce63036ae2af19b2205f6c9572f817ece472ff4ae51ff82f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
