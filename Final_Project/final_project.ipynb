{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. import packages\n",
    "\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1.1 GPU stuff\n",
    "\n",
    "# print (\"cuda: \", torch.cuda.is_available())\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# print (\"current device: \", device)\n",
    "# print (\"count: \", torch.cuda.device_count())\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     print (\"device name: \", torch.cuda.get_device_name(0))\n",
    "#     torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 load groove dataset\n",
    "import math\n",
    "\n",
    "groove_csv = pd.read_csv('groove/info.csv')\n",
    "print(\"groove dataset:\", len(groove_csv))\n",
    "\n",
    "# get train, test, and validation sets\n",
    "train_csv = []\n",
    "test_csv = []\n",
    "validation_csv = []\n",
    "\n",
    "for index, row in groove_csv.iterrows():\n",
    "    if str(row.audio_filename).lower() != \"nan\":\n",
    "        split = row['split']\n",
    "        if split == \"train\":\n",
    "            train_csv.append(row)\n",
    "        elif split == \"test\":\n",
    "            test_csv.append(row)\n",
    "        elif split == \"validation\":\n",
    "            validation_csv.append(row)\n",
    "        \n",
    "print (\"train: \", len(train_csv))\n",
    "print (\"test: \", len(test_csv))\n",
    "print (\"validation: \", len(validation_csv))\n",
    "\n",
    "print (train_csv[0].midi_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio files into tensor\n",
    "from pydub import AudioSegment\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "def load_audio_to_melspec_tensor(wavpath, sample_rate=44_100):\n",
    "    window_size = 0.025\n",
    "    window_stride = 0.01\n",
    "    n_dft = 2048\n",
    "    win_length = int(sample_rate * window_size)\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    y, sr = librosa.load(wavpath)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length, win_length=win_length, window=signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=40, fmin=20)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "\n",
    "    plot.imshow(logspec.T, origin='lower', aspect='auto')\n",
    "    plot.show()\n",
    "    \n",
    "    logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec_tensor\n",
    "\n",
    "i = 0\n",
    "for index in train_csv:\n",
    "    # 1. load in wavefile\n",
    "    audio_file_path = \"groove/\" + index.audio_filename\n",
    "    wav_file = AudioSegment.from_file(audio_file_path, format=\"wav\")\n",
    "    # convert sample width if not set to 2 (16 bits)\n",
    "    if wav_file.sample_width != 2:\n",
    "        wav_file = wav_file.set_sample_width(2)\n",
    "        # print(\"\\tnew sample_width: \", wav_file.sample_width)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # convert file from stereo to mono if channels > 1\n",
    "    if wav_file.channels != 1:\n",
    "        wav_file = wav_file.set_channels(1)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "\n",
    "    print (\"frame rate: \", wav_file.frame_rate)\n",
    "    tensor = load_audio_to_melspec_tensor(audio_file_path, wav_file.frame_rate)\n",
    "    \n",
    "    print (i, \"\\tfile: \", index.audio_filename, \"\\tduration: \", wav_file.duration_seconds, \"\\tensor: \", tensor.shape)\n",
    "\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2eb717040054f9e1cd6390da57b4c3f6de62338193843f816e8f12a4d5407ba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
