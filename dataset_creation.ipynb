{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 import packages\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "import mido\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "import audiosegment\n",
    "import librosa\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 midi mappings from groove dataset\n",
    "# kick drum\n",
    "BASS = 36\n",
    "# snare drum\n",
    "SNARE_HEAD = 38\n",
    "SNARE_RIM = 40\n",
    "SNARE_X_STICK = 37\n",
    "# toms\n",
    "TOM_1_HEAD = 48\n",
    "TOM_1_RIM = 50\n",
    "TOM_2_HEAD = 45\n",
    "TOM_2_RIM = 47\n",
    "TOM_3_HEAD = 43\n",
    "TOM_3_RIM = 58\n",
    "# hi-hats\n",
    "HH_OPEN_BOW = 46\n",
    "HH_OPEN_EDGE = 26\n",
    "HH_CLOSED_BOW = 42\n",
    "HH_CLOSED_EDGE = 22\n",
    "HH_PEDAL = 44\n",
    "# crash cymbal\n",
    "CRASH_1_BOW = 49\n",
    "CRASH_1_EDGE = 55\n",
    "CRASH_2_BOW = 57\n",
    "CRASH_2_EDGE = 52\n",
    "# ride cymbal\n",
    "RIDE_BOW = 51\n",
    "RIDE_EDGE = 59\n",
    "RIDE_BELL = 53\n",
    "\n",
    "# mappings for our own training (9)\n",
    "KICK = 0\n",
    "SNARE = 1\n",
    "HH_CLOSED = 2\n",
    "HH_OPEN = 3\n",
    "RIDE = 4\n",
    "TOM_1 = 5\n",
    "TOM_2 = 6\n",
    "TOM_3 = 7\n",
    "CRASH = 8\n",
    "NUM_FEATS = 9\n",
    "\n",
    "# groove mappings to our mappings\n",
    "KICK_LIST = [BASS]\n",
    "SNARE_LIST = [SNARE_HEAD, SNARE_RIM, SNARE_X_STICK]\n",
    "HH_CLOSED_LIST = [HH_CLOSED_BOW, HH_CLOSED_EDGE, HH_PEDAL]\n",
    "HH_OPEN_LIST = [HH_OPEN_BOW, HH_OPEN_EDGE]\n",
    "RIDE_LIST = [RIDE_BOW, RIDE_EDGE, RIDE_BELL]\n",
    "TOM_1_LIST = [TOM_1_HEAD, TOM_1_RIM]\n",
    "TOM_2_LIST = [TOM_2_HEAD, TOM_2_RIM]\n",
    "TOM_3_LIST = [TOM_3_HEAD, TOM_3_RIM]\n",
    "CRASH_LIST = [CRASH_1_BOW, CRASH_1_EDGE, CRASH_2_BOW, CRASH_2_EDGE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 load groove dataset\n",
    "\n",
    "groove_csv = pd.read_csv('data/groove/info.csv')\n",
    "print(\"groove dataset:\", len(groove_csv))\n",
    "\n",
    "# get train, test, and validation sets\n",
    "train_csv = []\n",
    "test_csv = []\n",
    "validation_csv = []\n",
    "\n",
    "for index, row in groove_csv.iterrows():\n",
    "    if str(row.audio_filename).lower() != \"nan\":\n",
    "        split = row['split']\n",
    "        if split == \"train\":\n",
    "            train_csv.append(row)\n",
    "        elif split == \"test\":\n",
    "            test_csv.append(row)\n",
    "        elif split == \"validation\":\n",
    "            validation_csv.append(row)\n",
    "        \n",
    "print (\"train: \", len(train_csv))\n",
    "print (\"test: \", len(test_csv))\n",
    "print (\"validation: \", len(validation_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 code to convert midi file to array\n",
    "# https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c\n",
    "\n",
    "def msg2dict(msg):\n",
    "    result = dict()\n",
    "    if 'note_on' in msg:\n",
    "        on_ = True\n",
    "    elif 'note_off' in msg:\n",
    "        on_ = False\n",
    "    else:\n",
    "        on_ = None\n",
    "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
    "        str.maketrans({a: None for a in string.punctuation})))\n",
    "\n",
    "    if on_ is not None:\n",
    "        for k in ['note', 'velocity']:\n",
    "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
    "                str.maketrans({a: None for a in string.punctuation})))\n",
    "    return [result, on_]\n",
    "\n",
    "def switch_note(last_state, note, velocity, on_=True):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
    "    result = [0] * 88 if last_state is None else last_state.copy()\n",
    "    if 21 <= note <= 108:\n",
    "        value = 1 if velocity > 0 else 0\n",
    "        result[note-21] = value if on_ else 0\n",
    "    return result\n",
    "\n",
    "def get_new_state(new_msg, last_state):\n",
    "    new_msg, on_ = msg2dict(str(new_msg))\n",
    "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
    "    return [new_state, new_msg['time']]\n",
    "\n",
    "def track2seq(track):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of the id range will be ignored\n",
    "    result = []\n",
    "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
    "    for i in range(1, len(track)):\n",
    "        new_state, new_time = get_new_state(track[i], last_state)\n",
    "        if new_time > 0:\n",
    "            result += [last_state]*new_time\n",
    "        last_state, last_time = new_state, new_time\n",
    "    return result\n",
    "\n",
    "def mid2array(mid, min_msg_pct=0.1):\n",
    "    tracks_len = [len(tr) for tr in mid.tracks]\n",
    "    min_n_msg = max(tracks_len) * min_msg_pct\n",
    "    # convert each track to nested list\n",
    "    all_arys = []\n",
    "    for i in range(len(mid.tracks)):\n",
    "        if len(mid.tracks[i]) > min_n_msg:\n",
    "            ary_i = track2seq(mid.tracks[i])\n",
    "            all_arys.append(ary_i)\n",
    "    # make all nested list the same length\n",
    "    max_len = max([len(ary) for ary in all_arys])\n",
    "    for i in range(len(all_arys)):\n",
    "        if len(all_arys[i]) < max_len:\n",
    "            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
    "    all_arys = np.array(all_arys)\n",
    "    all_arys = all_arys.max(axis=0)\n",
    "    # trim: remove consecutive 0s in the beginning and at the end\n",
    "    # sums = all_arys.sum(axis=1)\n",
    "    # ends = np.where(sums > 0)[0]\n",
    "    return all_arys #[min(ends): max(ends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 functions for feature and label extraction\n",
    "\n",
    "default_sample_rate = 44100\n",
    "predefined_length = 4.99 # had to make a bit smaller than 10 sec. because was sizing array to 1001 instead of 1000\n",
    "tensor_size = 250 # used for label tensor creation\n",
    "\n",
    "# resets temp folder\n",
    "def reset_temp_folder():\n",
    "    if os.path.isfile('temp/'):\n",
    "        shutil.rmtree('temp/', ignore_errors=True)\n",
    "    if not os.path.exists('temp/'):\n",
    "        os.mkdir('temp/')\n",
    "\n",
    "# converts an audio file to log mel array\n",
    "def audio_to_melspec_array(wav_file_path, sample_rate=default_sample_rate):\n",
    "    window_size = 0.05\n",
    "    window_stride = 0.02\n",
    "    n_dft = int(sample_rate * window_size)\n",
    "    n_mels = 128\n",
    "    win_length = 1024\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    # load in wav file and remove the mean of the signal\n",
    "    y, sr = librosa.load(wav_file_path, sr=sample_rate)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length, win_length=win_length, window=signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=n_mels, fmin=20)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "    # plot.imshow(logspec.T, origin='lower', aspect='auto')\n",
    "    # plot.show()\n",
    "    # turn into tensor\n",
    "    # logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec\n",
    "\n",
    "# reformats midi array for training\n",
    "def reformat_midi_for_training(midi_array):\n",
    "    midi_array = midi_array.T # transpose midi array for easy access\n",
    "    T_steps = midi_array.shape[1] # get number of time steps\n",
    "    # kicks\n",
    "    kick_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in KICK_LIST:\n",
    "        kick_midi += midi_array[val-21]\n",
    "    kick_midi = np.where(kick_midi > 0, 1, 0)\n",
    "    # snares\n",
    "    snare_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in SNARE_LIST:\n",
    "        snare_midi += midi_array[val-21]\n",
    "    snare_midi = np.where(snare_midi > 0, 1, 0)\n",
    "    # hh_close\n",
    "    hh_close_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in HH_CLOSED_LIST:\n",
    "        hh_close_midi += midi_array[val-21]\n",
    "    hh_close_midi = np.where(hh_close_midi > 0, 1, 0)\n",
    "    # hh_open\n",
    "    hh_open_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in HH_OPEN_LIST:\n",
    "        hh_open_midi += midi_array[val-21]\n",
    "    hh_open_midi = np.where(hh_open_midi > 0, 1, 0)\n",
    "    # ride\n",
    "    ride_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in RIDE_LIST:\n",
    "        ride_midi += midi_array[val-21]\n",
    "    ride_midi = np.where(ride_midi > 0, 1, 0)\n",
    "    # tom 1\n",
    "    tom1_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_1_LIST:\n",
    "        tom1_midi += midi_array[val-21]\n",
    "    tom1_midi = np.where(tom1_midi > 0, 1, 0)\n",
    "    # tom 2\n",
    "    tom2_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_2_LIST:\n",
    "        tom2_midi += midi_array[val-21]\n",
    "    tom2_midi = np.where(tom2_midi > 0, 1, 0)\n",
    "    # tom 3\n",
    "    tom3_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_3_LIST:\n",
    "        tom3_midi += midi_array[val-21]\n",
    "    tom3_midi = np.where(tom3_midi > 0, 1, 0)\n",
    "    # crash\n",
    "    crash_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in CRASH_LIST:\n",
    "        crash_midi += midi_array[val-21]\n",
    "    crash_midi = np.where(crash_midi > 0, 1, 0)\n",
    "    \n",
    "    reformated_midi_array = np.zeros((midi_array.shape[1], NUM_FEATS), dtype='int64')\n",
    "    reformated_midi_array[:,KICK] = kick_midi\n",
    "    reformated_midi_array[:,SNARE] = snare_midi\n",
    "    reformated_midi_array[:,HH_CLOSED] = hh_close_midi\n",
    "    reformated_midi_array[:,HH_OPEN] = hh_open_midi\n",
    "    reformated_midi_array[:,RIDE] = ride_midi\n",
    "    reformated_midi_array[:,TOM_1] = tom1_midi\n",
    "    reformated_midi_array[:,TOM_2] = tom2_midi\n",
    "    reformated_midi_array[:,TOM_3] = tom3_midi\n",
    "    reformated_midi_array[:,CRASH] = crash_midi\n",
    "    # reformated_midi_array = np.vstack([\n",
    "    #     kick_midi,\n",
    "    #     snare_midi,\n",
    "    #     hh_close_midi,\n",
    "    #     hh_open_midi,\n",
    "    #     ride_midi,\n",
    "    #     tom1_midi,\n",
    "    #     tom2_midi,\n",
    "    #     tom3_midi,\n",
    "    #     crash_midi\n",
    "    # ])\n",
    "    # reformated_midi_array = np.array(reformated_midi_array.T, dtype='int64')\n",
    "    \n",
    "    # print (\"hh_open_midi.shape: \", hh_open_midi.shape)\n",
    "    # print (\"hh_open_midi: \", hh_open_midi)\n",
    "    \n",
    "    return reformated_midi_array\n",
    "\n",
    "# shrinks an array down keeping the distance between values proportional\n",
    "def shrink_array_proportionally(midi_array, target_resize):\n",
    "    resized_array = np.zeros((target_resize, midi_array.shape[1]))\n",
    "    ratio = midi_array.shape[0] / target_resize\n",
    "    # iterate through each time-step\n",
    "    for t in range(midi_array.shape[0]): \n",
    "        # for each value\n",
    "        for i in range(midi_array.shape[1]):\n",
    "            value = midi_array[t][i]\n",
    "            if value > 0:\n",
    "                t2 = int(t / ratio)\n",
    "                resized_array[t2][i] = value\n",
    "    return resized_array\n",
    "\n",
    "# converts a midi array to a list of arrays\n",
    "def midi_to_arrays(midi_array, num_arrays):\n",
    "    midi_arrays = []\n",
    "    split_midi_arrays = np.array_split(midi_array, num_arrays)\n",
    "    #print (\"midi array len: \", len(midi_array))\n",
    "    #print (\"split list len: \", len(split_midi_arrays))\n",
    "    for i in range(len(split_midi_arrays)):\n",
    "        #print (\"shape: \", split_midi_arrays[i].shape)\n",
    "        # only add array if correct size\n",
    "        if split_midi_arrays[i].shape == (tensor_size, NUM_FEATS):\n",
    "            midi_arrays.append(split_midi_arrays[i])\n",
    "    return midi_arrays\n",
    "\n",
    "def show_midi_plot(midi_array):\n",
    "    midi_array = np.flip(midi_array.T, axis=0)\n",
    "    f = plot.figure()\n",
    "    f.set_figwidth(20)\n",
    "    f.set_figheight(10)\n",
    "    plot.imshow(midi_array, cmap='binary', interpolation='None', aspect=\"auto\")\n",
    "    plot.show()\n",
    "    \n",
    "def show_spectrograph(spec_array):\n",
    "    spec_array = np.flip(spec_array.T, axis=0)\n",
    "    f = plot.figure()\n",
    "    f.set_figwidth(20)\n",
    "    f.set_figheight(10)\n",
    "    plot.imshow(spec_array, cmap='magma', interpolation='None', aspect=\"auto\")\n",
    "    plot.show()\n",
    "    \n",
    "def show_midi_over_spec(spec_array, midi_array):\n",
    "    midi_array = np.flip(midi_array.T, axis=0)\n",
    "    spec_array = np.flip(spec_array.T, axis=0)\n",
    "    fig = plot.figure()\n",
    "    fig.set_figwidth(20)\n",
    "    fig.set_figheight(10)\n",
    "    plot.imshow(spec_array, 'magma', interpolation='None', aspect=\"auto\")\n",
    "    plot.imshow(midi_array, 'binary', interpolation='None', alpha=0.5, aspect=\"auto\")\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "def index_to_arrays(csv_index):\n",
    "    # load in wav file\n",
    "    audio_file_path = \"data/groove/\" + csv_index.audio_filename\n",
    "    wav_file = audiosegment.from_file(audio_file_path)\n",
    "    #print (\"sample rate: \", wav_file.frame_rate)\n",
    "    #print (\"wav duration: \", wav_file.duration_seconds)\n",
    "    # convert sample width if not set to 2 (16 bits)\n",
    "    if wav_file.sample_width != 2:\n",
    "        wav_file = wav_file.set_sample_width(2)\n",
    "        # print(\"\\tnew sample_width: \", wav_file.sample_width)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # convert file from stereo to mono if channels > 1\n",
    "    if wav_file.channels != 1:\n",
    "        wav_file = wav_file.set_channels(1)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # cutting and padding\n",
    "    diced_wav_files = wav_file.dice(predefined_length, zero_pad=False)\n",
    "    #print (\"diced wav files len: \", len(diced_wav_files))\n",
    "    target_len = predefined_length * wav_file.frame_rate\n",
    "    feats_list = []\n",
    "    zeros_padded_amount = 0\n",
    "    i = 0\n",
    "    for diced_file in diced_wav_files:\n",
    "        # pad with zeros if not correct length\n",
    "        diced_file_len = len(diced_file.to_numpy_array())\n",
    "        #print (\"\\tdiced file len: \", diced_file_len)\n",
    "        if diced_file_len != target_len:\n",
    "            zeros = int(target_len - diced_file_len)\n",
    "            zeros_padded_amount = ((zeros / target_len) * predefined_length) / wav_file.duration_seconds\n",
    "            #print (\"zeros_padded_amount: \", zeros_padded_amount * 100, \" %\")\n",
    "            diced_array = np.pad(diced_file.to_numpy_array(), (0, zeros))\n",
    "            diced_file = audiosegment.from_numpy_array(diced_array, framerate=default_sample_rate)\n",
    "        # export temp wav file and convert to tensor\n",
    "        diced_file_path = str(csv_index.id) + \"-\" + str(i) + \".wav\"\n",
    "        diced_file_path = diced_file_path.replace('/', '-')\n",
    "        diced_file_path = \"temp/\" + diced_file_path\n",
    "        diced_file.export(diced_file_path, format=\"wav\")\n",
    "        feats_array = audio_to_melspec_array(diced_file_path, wav_file.frame_rate)\n",
    "        feats_list.append(feats_array)\n",
    "        i += 1\n",
    "    # return numpy array\n",
    "    feats_list = np.array(feats_list, dtype='float64')\n",
    "    \n",
    "    # load in midi file\n",
    "    midi_file_path = \"data/groove/\" + csv_index.midi_filename\n",
    "    midi = mido.MidiFile(midi_file_path)\n",
    "    # convert midi to array\n",
    "    midi_array = mid2array(midi)\n",
    "    #show_midi_plot(midi_array)\n",
    "    \n",
    "    # reformat midi array for training\n",
    "    midi_array = reformat_midi_for_training(midi_array)\n",
    "    #show_midi_plot(midi_array)\n",
    "    #print (\"reformated midi_array.shape: \", midi_array.shape)\n",
    "    \n",
    "    # cut or pad midi array to match wav file length\n",
    "    if midi.length > wav_file.duration_seconds:\n",
    "        cut_amount = midi.length - wav_file.duration_seconds\n",
    "        cut_amount = cut_amount / midi.length\n",
    "        cut_amount = int(cut_amount * midi_array.shape[0])\n",
    "        midi_array = midi_array[0: midi_array.shape[0] - cut_amount, :]\n",
    "    \n",
    "    # pad midi array to be proportionally same length as wav file w padded zeros \n",
    "    if zeros_padded_amount > 0:\n",
    "        zeros = int(midi_array.shape[0] * zeros_padded_amount)\n",
    "        zeros_pad = np.zeros((zeros, midi_array.shape[1]))\n",
    "        midi_array = np.concatenate((midi_array, zeros_pad))\n",
    "    #show_midi_plot(midi_array)\n",
    "\n",
    "    # resize array to be directly related to duration of the audio file (every second is 100 units)\n",
    "    target_resize = int(feats_list.shape[0] * tensor_size)\n",
    "    #print (\"current midi array size: \", midi_array.shape[0], \" target size: \", target_resize)\n",
    "    midi_array = shrink_array_proportionally(midi_array, target_resize)\n",
    "    #show_midi_plot(midi_array)\n",
    "    #print (\"shrinked midi_array.shape: \", midi_array.shape)\n",
    "\n",
    "    # create label arrays\n",
    "    labels_list = midi_to_arrays(midi_array, len(feats_list))\n",
    "    # return numpy arrays\n",
    "    labels_list = np.array(labels_list, dtype='int64')\n",
    "    \n",
    "    #print (\"labels: \", labels_list.shape)\n",
    "    \n",
    "    return feats_list , labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 run dataset creation loops - save to file\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# data id (used to make different datasets)\n",
    "data_id = '_5s_250hz'\n",
    "\n",
    "# reset temp folder\n",
    "reset_temp_folder()\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#           TRAINING DATA               #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# get complete list of train feats / labels\n",
    "print (\"starting training dataset creation...\")\n",
    "startTime = time.time()\n",
    "train_feats = []\n",
    "train_labels = []\n",
    "for i, index in enumerate(tqdm(train_csv)):\n",
    "    # print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = index_to_arrays(index)\n",
    "    for j in range(len(feats)):\n",
    "        # print (\"\\t\", j, \" feats: \", feats[j].shape, \" labels: \", labels[j].shape)\n",
    "        # show_midi_plot(labels[j])\n",
    "        # show_spectrograph(feats[j])\n",
    "        # show_midi_over_spec(feats[j], labels[j])\n",
    "        train_feats.append(feats[j])\n",
    "        train_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "train_feats = np.array(train_feats, dtype='float64')\n",
    "train_labels = np.array(train_labels, dtype='int64')\n",
    "print (\"train_feats.shape: \", train_feats.shape)\n",
    "print (\"train_labels.shape: \", train_labels.shape)\n",
    "# dataset complete\n",
    "print (\"training dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# create dataset folder if it does not exist\n",
    "if not os.path.exists('data/dataset', data_id):\n",
    "        os.mkdir('data/dataset', data_id)\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"train_feats\", data_id, \".npy\", train_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"train_labels\", data_id, \".npy\", train_labels, allow_pickle=True)\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#               TEST DATA               #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# get complete list of test feats / labels\n",
    "print (\"starting test dataset creation...\")\n",
    "startTime = time.time()\n",
    "test_feats = []\n",
    "test_labels = []\n",
    "for i, index in enumerate(tqdm(test_csv)):\n",
    "    #print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = index_to_arrays(index)\n",
    "    for j in range(len(feats)):\n",
    "        # show_midi_over_spec(feats[j], labels[j])\n",
    "        test_feats.append(feats[j])\n",
    "        test_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "test_feats = np.array(test_feats, dtype='float64')\n",
    "test_labels = np.array(test_labels, dtype='int64')\n",
    "print (\"test_feats.shape: \", test_feats.shape)\n",
    "print (\"test_labels.shape: \", test_labels.shape)\n",
    "# dataset complete\n",
    "print (\"test dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"test_feats\", data_id, \".npy\", test_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"test_labels\", data_id, \".npy\", test_labels, allow_pickle=True)\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#           VALIDATION DATA             #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# # get complete list of validation feats / labels\n",
    "print (\"starting validation dataset creation...\")\n",
    "startTime = time.time()\n",
    "val_feats = []\n",
    "val_labels = []\n",
    "for i, index in enumerate(tqdm(validation_csv)):\n",
    "    #print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = index_to_arrays(index)\n",
    "    for j in range(len(feats)):\n",
    "        # show_midi_over_spec(feats[j], labels[j])\n",
    "        val_feats.append(feats[j])\n",
    "        val_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "val_feats = np.array(val_feats, dtype='float64')\n",
    "val_labels = np.array(val_labels, dtype='int64')\n",
    "print (\"val_feats.shape: \", val_feats.shape)\n",
    "print (\"val_labels.shape: \", val_labels.shape)\n",
    "# dataset complete\n",
    "print (\"validation dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"val_feats\", data_id, \".npy\", val_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\", data_id, \"/\", \"val_labels\", data_id, \".npy\", val_labels, allow_pickle=True)\n",
    "\n",
    "# reset temp folder\n",
    "reset_temp_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da06df106b6ebc505395780f3c76810614ede012a8d0e2bc265d4156a4243031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
