{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0 import packages\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "import mido\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "import audiosegment\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 midi mappings from groove dataset\n",
    "# kick drum\n",
    "BASS = 36\n",
    "# snare drum\n",
    "SNARE_HEAD = 38\n",
    "SNARE_RIM = 40\n",
    "SNARE_X_STICK = 37\n",
    "# toms\n",
    "TOM_1_HEAD = 48\n",
    "TOM_1_RIM = 50\n",
    "TOM_2_HEAD = 45\n",
    "TOM_2_RIM = 47\n",
    "TOM_3_HEAD = 43\n",
    "TOM_3_RIM = 58\n",
    "# hi-hats\n",
    "HH_OPEN_BOW = 46\n",
    "HH_OPEN_EDGE = 26\n",
    "HH_CLOSED_BOW = 42\n",
    "HH_CLOSED_EDGE = 22\n",
    "HH_PEDAL = 44\n",
    "# crash cymbal\n",
    "CRASH_1_BOW = 49\n",
    "CRASH_1_EDGE = 55\n",
    "CRASH_2_BOW = 57\n",
    "CRASH_2_EDGE = 52\n",
    "# ride cymbal\n",
    "RIDE_BOW = 51\n",
    "RIDE_EDGE = 59\n",
    "RIDE_BELL = 53\n",
    "\n",
    "# mappings for our own training (9)\n",
    "KICK = 0\n",
    "SNARE = 1\n",
    "HH_CLOSED = 2\n",
    "HH_OPEN = 3\n",
    "RIDE = 4\n",
    "TOM_1 = 5\n",
    "TOM_2 = 6\n",
    "TOM_3 = 7\n",
    "CRASH = 8\n",
    "NUM_FEATS = 9\n",
    "\n",
    "# groove mappings to our mappings\n",
    "KICK_LIST = [BASS]\n",
    "SNARE_LIST = [SNARE_HEAD, SNARE_RIM, SNARE_X_STICK]\n",
    "HH_CLOSED_LIST = [HH_CLOSED_BOW, HH_CLOSED_EDGE, HH_PEDAL]\n",
    "HH_OPEN_LIST = [HH_OPEN_BOW, HH_OPEN_EDGE]\n",
    "RIDE_LIST = [RIDE_BOW, RIDE_EDGE, RIDE_BELL]\n",
    "TOM_1_LIST = [TOM_1_HEAD, TOM_1_RIM]\n",
    "TOM_2_LIST = [TOM_2_HEAD, TOM_2_RIM]\n",
    "TOM_3_LIST = [TOM_3_HEAD, TOM_3_RIM]\n",
    "CRASH_LIST = [CRASH_1_BOW, CRASH_1_EDGE, CRASH_2_BOW, CRASH_2_EDGE]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 load groove dataset\n",
    "\n",
    "groove_csv = pd.read_csv('data/groove/info.csv')\n",
    "print(\"groove dataset:\", len(groove_csv))\n",
    "\n",
    "# get train, test, and validation sets\n",
    "train_csv = []\n",
    "test_csv = []\n",
    "validation_csv = []\n",
    "\n",
    "for index, row in groove_csv.iterrows():\n",
    "    if str(row.audio_filename).lower() != \"nan\":\n",
    "        split = row['split']\n",
    "        if split == \"train\":\n",
    "            train_csv.append(row)\n",
    "        elif split == \"test\":\n",
    "            test_csv.append(row)\n",
    "        elif split == \"validation\":\n",
    "            validation_csv.append(row)\n",
    "        \n",
    "print (\"train: \", len(train_csv))\n",
    "print (\"test: \", len(test_csv))\n",
    "print (\"validation: \", len(validation_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 code to convert midi file to array\n",
    "# https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c\n",
    "\n",
    "def msg2dict(msg):\n",
    "    result = dict()\n",
    "    if 'note_on' in msg:\n",
    "        on_ = True\n",
    "    elif 'note_off' in msg:\n",
    "        on_ = False\n",
    "    else:\n",
    "        on_ = None\n",
    "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
    "        str.maketrans({a: None for a in string.punctuation})))\n",
    "\n",
    "    if on_ is not None:\n",
    "        for k in ['note', 'velocity']:\n",
    "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
    "                str.maketrans({a: None for a in string.punctuation})))\n",
    "    return [result, on_]\n",
    "\n",
    "def switch_note(last_state, note, velocity, on_=True):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
    "    result = [0] * 88 if last_state is None else last_state.copy()\n",
    "    if 21 <= note <= 108:\n",
    "        value = 1 if velocity > 0 else 0\n",
    "        result[note-21] = value if on_ else 0\n",
    "    return result\n",
    "\n",
    "def get_new_state(new_msg, last_state):\n",
    "    new_msg, on_ = msg2dict(str(new_msg))\n",
    "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
    "    return [new_state, new_msg['time']]\n",
    "\n",
    "def track2seq(track):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of the id range will be ignored\n",
    "    result = []\n",
    "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
    "    for i in range(1, len(track)):\n",
    "        new_state, new_time = get_new_state(track[i], last_state)\n",
    "        if new_time > 0:\n",
    "            result += [last_state]*new_time\n",
    "        last_state, last_time = new_state, new_time\n",
    "    return result\n",
    "\n",
    "def mid2array(mid, min_msg_pct=0.1):\n",
    "    tracks_len = [len(tr) for tr in mid.tracks]\n",
    "    min_n_msg = max(tracks_len) * min_msg_pct\n",
    "    # convert each track to nested list\n",
    "    all_arys = []\n",
    "    for i in range(len(mid.tracks)):\n",
    "        if len(mid.tracks[i]) > min_n_msg:\n",
    "            ary_i = track2seq(mid.tracks[i])\n",
    "            all_arys.append(ary_i)\n",
    "    # make all nested list the same length\n",
    "    max_len = max([len(ary) for ary in all_arys])\n",
    "    for i in range(len(all_arys)):\n",
    "        if len(all_arys[i]) < max_len:\n",
    "            all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
    "    all_arys = np.array(all_arys)\n",
    "    all_arys = all_arys.max(axis=0)\n",
    "    # trim: remove consecutive 0s in the beginning and at the end\n",
    "    # sums = all_arys.sum(axis=1)\n",
    "    # ends = np.where(sums > 0)[0]\n",
    "    return all_arys #[min(ends): max(ends)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 functions for feature and label extraction\n",
    "\n",
    "default_sample_rate = 44100\n",
    "\n",
    "# resets temp folder\n",
    "def reset_temp_folder():\n",
    "    if os.path.isfile('temp/'):\n",
    "        shutil.rmtree('temp/', ignore_errors=True)\n",
    "    if not os.path.exists('temp/'):\n",
    "        os.mkdir('temp/')\n",
    "\n",
    "# converts an audio file to log mel array\n",
    "def audio_to_melspec_array(wav_file_path, window_size, window_stride, sample_rate=default_sample_rate):\n",
    "    n_dft = int(sample_rate * window_size)\n",
    "    n_mels = 128\n",
    "    win_length = 256\n",
    "    hop_length = int(sample_rate * window_stride)\n",
    "    # load in wav file and remove the mean of the signal\n",
    "    y, sr = librosa.load(wav_file_path, sr=sample_rate)\n",
    "    y = y - y.mean()\n",
    "    y = np.append(y[0],y[1:]-.97*y[:-1])\n",
    "    # compute mel spectrogram\n",
    "    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length, win_length=win_length, window=signal.hamming)\n",
    "    spec = np.abs(stft)**2\n",
    "    mel_basis = librosa.filters.mel(sr=sample_rate, n_fft=n_dft, n_mels=n_mels, fmin=0)\n",
    "    melspec = np.dot(mel_basis, spec)\n",
    "    logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    logspec = np.transpose(logspec)\n",
    "    # plot.imshow(logspec.T, origin='lower', aspect='auto')\n",
    "    # plot.show()\n",
    "    # turn into tensor\n",
    "    # logspec_tensor = torch.tensor(logspec)\n",
    "    return logspec\n",
    "\n",
    "# reformats midi array for training\n",
    "def reformat_midi(midi_array):\n",
    "    midi_array = midi_array.T # transpose midi array for easy access\n",
    "    T_steps = midi_array.shape[1] # get number of time steps\n",
    "    # kicks\n",
    "    kick_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in KICK_LIST:\n",
    "        kick_midi += midi_array[val-21]\n",
    "    kick_midi = np.where(kick_midi > 0, 1, 0)\n",
    "    # snares\n",
    "    snare_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in SNARE_LIST:\n",
    "        snare_midi += midi_array[val-21]\n",
    "    snare_midi = np.where(snare_midi > 0, 1, 0)\n",
    "    # hh_close\n",
    "    hh_close_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in HH_CLOSED_LIST:\n",
    "        hh_close_midi += midi_array[val-21]\n",
    "    hh_close_midi = np.where(hh_close_midi > 0, 1, 0)\n",
    "    # hh_open\n",
    "    hh_open_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in HH_OPEN_LIST:\n",
    "        hh_open_midi += midi_array[val-21]\n",
    "    hh_open_midi = np.where(hh_open_midi > 0, 1, 0)\n",
    "    # ride\n",
    "    ride_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in RIDE_LIST:\n",
    "        ride_midi += midi_array[val-21]\n",
    "    ride_midi = np.where(ride_midi > 0, 1, 0)\n",
    "    # tom 1\n",
    "    tom1_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_1_LIST:\n",
    "        tom1_midi += midi_array[val-21]\n",
    "    tom1_midi = np.where(tom1_midi > 0, 1, 0)\n",
    "    # tom 2\n",
    "    tom2_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_2_LIST:\n",
    "        tom2_midi += midi_array[val-21]\n",
    "    tom2_midi = np.where(tom2_midi > 0, 1, 0)\n",
    "    # tom 3\n",
    "    tom3_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in TOM_3_LIST:\n",
    "        tom3_midi += midi_array[val-21]\n",
    "    tom3_midi = np.where(tom3_midi > 0, 1, 0)\n",
    "    # crash\n",
    "    crash_midi = np.zeros((T_steps), dtype='int64')\n",
    "    for val in CRASH_LIST:\n",
    "        crash_midi += midi_array[val-21]\n",
    "    crash_midi = np.where(crash_midi > 0, 1, 0)\n",
    "    \n",
    "    reformated_midi_array = np.zeros((midi_array.shape[1], NUM_FEATS), dtype='int64')\n",
    "    reformated_midi_array[:,KICK] = kick_midi\n",
    "    reformated_midi_array[:,SNARE] = snare_midi\n",
    "    reformated_midi_array[:,HH_CLOSED] = hh_close_midi\n",
    "    reformated_midi_array[:,HH_OPEN] = hh_open_midi\n",
    "    reformated_midi_array[:,RIDE] = ride_midi\n",
    "    reformated_midi_array[:,TOM_1] = tom1_midi\n",
    "    reformated_midi_array[:,TOM_2] = tom2_midi\n",
    "    reformated_midi_array[:,TOM_3] = tom3_midi\n",
    "    reformated_midi_array[:,CRASH] = crash_midi\n",
    "    return reformated_midi_array\n",
    "\n",
    "# shrinks an array down keeping the distance between values proportional\n",
    "def shrink_array_proportionally(midi_array, target_resize):\n",
    "    resized_array = np.zeros((target_resize, midi_array.shape[1]))\n",
    "    ratio = midi_array.shape[0] / target_resize\n",
    "    # iterate through each time-step\n",
    "    for t in range(midi_array.shape[0]): \n",
    "        # for each value\n",
    "        for i in range(midi_array.shape[1]):\n",
    "            value = midi_array[t][i]\n",
    "            if value > 0:\n",
    "                t2 = int(t / ratio)\n",
    "                resized_array[t2][i] = value\n",
    "    return resized_array\n",
    "\n",
    "# converts a midi array to a list of arrays\n",
    "def midi_to_arrays(midi_array, num_arrays, array_length):\n",
    "    midi_arrays = []\n",
    "    split_midi_arrays = np.array_split(midi_array, num_arrays)\n",
    "    #print (\"midi array len: \", len(midi_array))\n",
    "    #print (\"split list len: \", len(split_midi_arrays))\n",
    "    for i in range(len(split_midi_arrays)):\n",
    "        #print (\"shape: \", split_midi_arrays[i].shape)\n",
    "        # only add array if correct size\n",
    "        if split_midi_arrays[i].shape == (array_length, NUM_FEATS):\n",
    "            midi_arrays.append(split_midi_arrays[i])\n",
    "    return midi_arrays\n",
    "\n",
    "# removes rows from midi_array if they are all 0\n",
    "def cut_leading_ending_zeros(midi_array):\n",
    "    # delete leading zeros\n",
    "    leading_zeros = 0\n",
    "    example = np.zeros(NUM_FEATS, dtype='int32')\n",
    "    for t in range(midi_array.shape[0]):\n",
    "        row = np.array(midi_array[t,:], dtype='int32')\n",
    "        if np.array_equal(row, example):\n",
    "            leading_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "    if leading_zeros > 0:\n",
    "        midi_array = np.delete(midi_array, np.s_[0:leading_zeros], axis=0)\n",
    "    # delete ending zeros\n",
    "    ending_zeros = 0\n",
    "    for t in range(midi_array.shape[0]-1, -1, -1):\n",
    "        row = np.array(midi_array[t,:], dtype='int32')\n",
    "        if np.array_equal(row, example):\n",
    "            ending_zeros += 1\n",
    "        else:\n",
    "            break\n",
    "    #print('ending zeros: ', ending_zeros, ' shape b4: ', midi_array.shape)\n",
    "    if ending_zeros > 0:\n",
    "        midi_array = midi_array[:-ending_zeros]\n",
    "    #print('ending zeros: ', ending_zeros, ' shape after: ', midi_array.shape)\n",
    "    return midi_array, leading_zeros, ending_zeros\n",
    "\n",
    "# slice midi based on ticks per seg (x ticks = 1 segment index)\n",
    "def slice_midi(midi_array, ticks_per_seg):\n",
    "    # get midi segments\n",
    "    midi_segments = []\n",
    "    for t in range(0, midi_array.shape[0], ticks_per_seg):\n",
    "        segment = np.zeros(NUM_FEATS, dtype='int32')\n",
    "        for inst in range(NUM_FEATS):\n",
    "            sum = 0\n",
    "            for i in range(ticks_per_seg):\n",
    "                if (t+i < midi_array.shape[0]):\n",
    "                    sum += midi_array[t+i][inst]\n",
    "            sum /= ticks_per_seg\n",
    "            if (sum >= 0.5):\n",
    "                segment[inst] = 1\n",
    "        midi_segments.append(segment)\n",
    "    return midi_segments\n",
    "\n",
    "def remove_leading_silence(wav_array):\n",
    "    leading_silence = 0\n",
    "    for t in range(len(wav_array)):\n",
    "        if wav_array[t] == 0 or wav_array[t] == -1 or wav_array[t] == 1:\n",
    "            leading_silence += 1\n",
    "        else:\n",
    "            break\n",
    "    if leading_silence > 0:\n",
    "        wav_array = wav_array[leading_silence:]\n",
    "    return wav_array\n",
    "        \n",
    "def show_midi_plot(midi_array):\n",
    "    midi_array = np.flip(midi_array.T, axis=0)\n",
    "    f = plot.figure()\n",
    "    f.set_figwidth(10)\n",
    "    f.set_figheight(5)\n",
    "    plot.imshow(midi_array, cmap='binary', interpolation='None', aspect=\"auto\")\n",
    "    plot.show()\n",
    "    return f\n",
    "    \n",
    "def show_spectrograph(spec_array):\n",
    "    spec_array = np.flip(spec_array.T, axis=0)\n",
    "    f = plot.figure()\n",
    "    f.set_figwidth(10)\n",
    "    f.set_figheight(5)\n",
    "    plot.imshow(spec_array, cmap='magma', interpolation='None', aspect=\"auto\")\n",
    "    plot.show()\n",
    "    \n",
    "def show_midi_over_spec(spec_array, midi_array):\n",
    "    midi_array = np.flip(midi_array.T, axis=0)\n",
    "    spec_array = np.flip(spec_array.T, axis=0)\n",
    "    fig = plot.figure()\n",
    "    fig.set_figwidth(10)\n",
    "    fig.set_figheight(5)\n",
    "    plot.imshow(spec_array, 'magma', interpolation='None', aspect=\"auto\")\n",
    "    plot.imshow(midi_array, 'binary', interpolation='None', alpha=0.5, aspect=\"auto\")\n",
    "    plot.show()\n",
    "\n",
    "def get_data_segs(data_index, segment_length, window_length, hop_length, overlap, print_out=False):\n",
    "    # load in midi file\n",
    "    midi_file_path = \"data/groove/\" + data_index.midi_filename\n",
    "    midi = mido.MidiFile(midi_file_path)\n",
    "    \n",
    "    # convert midi to array\n",
    "    midi_array = mid2array(midi)\n",
    "    if print_out:\n",
    "        show_midi_plot(midi_array)\n",
    "    calculated_length = mido.tick2second(midi_array.shape[0], ticks_per_beat=midi.ticks_per_beat, tempo=mido.bpm2tempo(data_index.bpm))\n",
    "    # reformat midi array for training\n",
    "    midi_array = reformat_midi(midi_array)\n",
    "    if print_out:\n",
    "        show_midi_plot(midi_array)\n",
    "    # cut leading zeros\n",
    "    midi_array, leading_zeros, ending_zeros = cut_leading_ending_zeros(midi_array)\n",
    "    leading_removed = mido.tick2second(leading_zeros, ticks_per_beat=midi.ticks_per_beat, tempo=mido.bpm2tempo(data_index.bpm))\n",
    "    ending_removed = mido.tick2second(ending_zeros, ticks_per_beat=midi.ticks_per_beat, tempo=mido.bpm2tempo(data_index.bpm))\n",
    "    new_midi_duration = mido.tick2second(midi_array.shape[0], ticks_per_beat=midi.ticks_per_beat, tempo=mido.bpm2tempo(data_index.bpm))\n",
    "    if print_out:\n",
    "        print ('starting length: ', midi.length)\n",
    "        print ('calculated starting length: ', calculated_length)\n",
    "        print ('leading removed: ', leading_removed)\n",
    "        print ('ending removed: ', ending_removed)\n",
    "        print ('new_midi duration: ', new_midi_duration)\n",
    "        print (\"removed starting zeros midi_array.shape: \", midi_array.shape)\n",
    "        show_midi_plot(midi_array)\n",
    "    # slice into segments of equal size\n",
    "    ticks_per_sec = int(mido.second2tick(segment_length, ticks_per_beat=midi.ticks_per_beat, tempo=mido.bpm2tempo(data_index.bpm)))\n",
    "    if print_out:\n",
    "        print ('ticks per sec: ', ticks_per_sec)\n",
    "    midi_segments = slice_midi(midi_array, ticks_per_sec)\n",
    "    if print_out:\n",
    "        print ('len(midi_segments): ', len(midi_segments))\n",
    "    if print_out:\n",
    "        show_midi_plot(np.array(midi_segments, dtype='int32'))\n",
    "\n",
    "\n",
    "    # load in wav file\n",
    "    audio_file_path = \"data/groove/\" + data_index.audio_filename\n",
    "    wav_file = audiosegment.from_file(audio_file_path)\n",
    "    if print_out:\n",
    "        print ('wav file duration: ', wav_file.duration_seconds, ' framerate: ', wav_file.frame_rate)\n",
    "    # convert sample width if not set to 2 (16 bits)\n",
    "    if wav_file.sample_width != 2:\n",
    "        wav_file = wav_file.set_sample_width(2)\n",
    "        # print(\"\\tnew sample_width: \", wav_file.sample_width)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # convert file from stereo to mono if channels > 1\n",
    "    if wav_file.channels != 1:\n",
    "        wav_file = wav_file.set_channels(1)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # remove starting silence from wav file\n",
    "    wav_array = wav_file.to_numpy_array()\n",
    "    wav_array = remove_leading_silence(wav_array)\n",
    "    wav_file = audiosegment.from_numpy_array(wav_array, framerate=wav_file.frame_rate)\n",
    "    if print_out:\n",
    "        print ('new wav file duration: ', wav_file.duration_seconds)\n",
    "    # cut wavfile to be same length in seconds as midi\n",
    "    if wav_file.duration_seconds > new_midi_duration:\n",
    "        resized_wav_file = wav_file.dice(new_midi_duration, zero_pad=False)\n",
    "        wav_file = resized_wav_file[0]\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    \n",
    "    # # show wav file spec\n",
    "    # if print_out:\n",
    "    #     freqs, times, amps = wav_file.spectrogram(window_length_s=window_length, overlap=overlap)\n",
    "    #     amps = 10 * np.log10(amps + 1e-9)\n",
    "    #     plot.pcolormesh(times, freqs, amps)\n",
    "    #     plot.xlabel(\"Time in Seconds\")\n",
    "    #     plot.ylabel(\"Frequency in Hz\")\n",
    "    #     plot.show()\n",
    "    \n",
    "    diced_wav_file = wav_file.dice(segment_length, zero_pad=True)\n",
    "    while len(diced_wav_file) > len(midi_segments):\n",
    "        diced_wav_file.pop()\n",
    "    while len(midi_segments) > len(diced_wav_file):\n",
    "        midi_segments.pop()\n",
    "    # convert midi segments to np array\n",
    "    midi_segments = np.array(midi_segments, dtype='int32')\n",
    "    \n",
    "    # apply mel filer to audio segments\n",
    "    formated_audio = []\n",
    "    for seg in diced_wav_file:\n",
    "        seg_np = seg.to_numpy_array()\n",
    "        seg_np = seg_np - seg_np.mean()\n",
    "        seg_np = np.append(seg_np[0],seg_np[1:]-.97*seg_np[:-1])\n",
    "        \n",
    "        #print ('seg_np.shape: ', seg_np.shape)\n",
    "        \n",
    "        n_fft = 2048\n",
    "        \n",
    "        # compute mel spectrogram\n",
    "        stft = librosa.stft(seg_np, n_fft=n_fft, hop_length=hop_length, win_length=window_length, window=signal.hamming)\n",
    "        spec = np.abs(stft)**2\n",
    "        \n",
    "        #print ('spec.shape: ', spec.shape)\n",
    "        \n",
    "        mel_basis = librosa.filters.mel(sr=default_sample_rate, n_fft=n_fft, n_mels=32, fmin=0, fmax=20000)\n",
    "        melspec = np.dot(mel_basis, spec)\n",
    "        logspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "        logspec = np.transpose(logspec)\n",
    "        \n",
    "        #print ('logspec.shape: ', logspec.shape)\n",
    "        \n",
    "        if print_out:\n",
    "            plot.imshow(logspec, origin='lower', aspect='auto')\n",
    "            plot.show()\n",
    "\n",
    "        formated_audio.append(logspec)\n",
    "    formated_audio_array = np.array(formated_audio, dtype='float32')\n",
    "    #print ('formated_audio_array.shape: ', formated_audio_array.shape)\n",
    "    return formated_audio_array, midi_segments\n",
    "    \n",
    "    # # reshape into frames\n",
    "    # if midi_segments.shape[0] == formated_audio_array.shape[0]:\n",
    "    #     framed_audio_list = []\n",
    "    #     final_element_index = int(midi_segments.shape[0] - 1)\n",
    "    #     for i, seg in enumerate(midi_segments):\n",
    "    #         frames = []\n",
    "    #         if i == 0:\n",
    "    #             frames.append(formated_audio_array[0])\n",
    "    #             frames.append(formated_audio_array[1])\n",
    "    #             frames.append(formated_audio_array[2])\n",
    "    #         elif i == final_element_index:\n",
    "    #             frames.append(formated_audio_array[final_element_index - 2])\n",
    "    #             frames.append(formated_audio_array[final_element_index - 1])\n",
    "    #             frames.append(formated_audio_array[final_element_index])\n",
    "    #         else:\n",
    "    #             frames.append(formated_audio_array[i-1])\n",
    "    #             frames.append(formated_audio_array[i])\n",
    "    #             frames.append(formated_audio_array[i+1])\n",
    "            \n",
    "    #         frames_np = np.array(frames, dtype='float32')\n",
    "    #         framed_audio_list.append(frames_np)\n",
    "            \n",
    "    #     framed_audio_array = np.array(framed_audio_list, dtype='float32')\n",
    "    # else:\n",
    "    #     return formated_audio_array, midi_segments\n",
    "    \n",
    "    # if print_out:\n",
    "    #     print ('midi_segments.shape: ', midi_segments.shape)\n",
    "    #     print ('framed_audio_array.shape: ', framed_audio_array.shape)\n",
    "    # return framed_audio_array, midi_segments\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def index_to_arrays(csv_index, segment_length, window_size, window_stride):\n",
    "    # load in wav file\n",
    "    audio_file_path = \"data/groove/\" + csv_index.audio_filename\n",
    "    wav_file = audiosegment.from_file(audio_file_path)\n",
    "    #print (\"sample rate: \", wav_file.frame_rate)\n",
    "    #print (\"wav duration: \", wav_file.duration_seconds)\n",
    "    # convert sample width if not set to 2 (16 bits)\n",
    "    if wav_file.sample_width != 2:\n",
    "        wav_file = wav_file.set_sample_width(2)\n",
    "        # print(\"\\tnew sample_width: \", wav_file.sample_width)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # convert file from stereo to mono if channels > 1\n",
    "    if wav_file.channels != 1:\n",
    "        wav_file = wav_file.set_channels(1)\n",
    "        wav_file.export(audio_file_path, format=\"wav\")\n",
    "    # cutting and padding\n",
    "    diced_wav_files = wav_file.dice(segment_length, zero_pad=False)\n",
    "    #print (\"diced wav files len: \", len(diced_wav_files))\n",
    "    target_len = segment_length * wav_file.frame_rate\n",
    "    feats_list = []\n",
    "    zeros_padded_amount = 0\n",
    "    i = 0\n",
    "    for diced_file in diced_wav_files:\n",
    "        # pad with zeros if not correct length\n",
    "        diced_file_len = len(diced_file.to_numpy_array())\n",
    "        #print (\"\\tdiced file len: \", diced_file_len)\n",
    "        if diced_file_len != target_len:\n",
    "            zeros = int(target_len - diced_file_len)\n",
    "            zeros_padded_amount = ((zeros / target_len) * segment_length) / wav_file.duration_seconds\n",
    "            #print (\"zeros_padded_amount: \", zeros_padded_amount * 100, \" %\")\n",
    "            diced_array = np.pad(diced_file.to_numpy_array(), (0, zeros))\n",
    "            diced_file = audiosegment.from_numpy_array(diced_array, framerate=default_sample_rate)\n",
    "        # export temp wav file and convert to tensor\n",
    "        diced_file_path = str(csv_index.id) + \"-\" + str(i) + \".wav\"\n",
    "        diced_file_path = diced_file_path.replace('/', '-')\n",
    "        diced_file_path = \"temp/\" + diced_file_path\n",
    "        diced_file.export(diced_file_path, format=\"wav\")\n",
    "        feats_array = audio_to_melspec_array(diced_file_path, window_size, window_stride, wav_file.frame_rate)\n",
    "        feats_list.append(feats_array)\n",
    "        i += 1\n",
    "    # return numpy array\n",
    "    feats_list = np.array(feats_list, dtype='float64')\n",
    "    \n",
    "    # load in midi file\n",
    "    midi_file_path = \"data/groove/\" + csv_index.midi_filename\n",
    "    midi = mido.MidiFile(midi_file_path)\n",
    "    # convert midi to array\n",
    "    midi_array = mid2array(midi)\n",
    "    #show_midi_plot(midi_array)\n",
    "    \n",
    "    # reformat midi array for training\n",
    "    midi_array = reformat_midi(midi_array)\n",
    "    #show_midi_plot(midi_array)\n",
    "    #print (\"reformated midi_array.shape: \", midi_array.shape)\n",
    "    \n",
    "    # cut or pad midi array to match wav file length\n",
    "    if midi.length > wav_file.duration_seconds:\n",
    "        cut_amount = midi.length - wav_file.duration_seconds\n",
    "        cut_amount = cut_amount / midi.length\n",
    "        cut_amount = int(cut_amount * midi_array.shape[0])\n",
    "        midi_array = midi_array[0: midi_array.shape[0] - cut_amount, :]\n",
    "    \n",
    "    # pad midi array to be proportionally same length as wav file w padded zeros \n",
    "    if zeros_padded_amount > 0:\n",
    "        zeros = int(midi_array.shape[0] * zeros_padded_amount)\n",
    "        zeros_pad = np.zeros((zeros, midi_array.shape[1]))\n",
    "        midi_array = np.concatenate((midi_array, zeros_pad))\n",
    "    #show_midi_plot(midi_array)\n",
    "\n",
    "    # resize array to be directly related to duration of the audio file (every second is 100 units)\n",
    "    target_resize = int(feats_list.shape[0] * feats_list.shape[1])\n",
    "    #print (\"current midi array size: \", midi_array.shape[0], \" target size: \", target_resize)\n",
    "    midi_array = shrink_array_proportionally(midi_array, target_resize)\n",
    "    #show_midi_plot(midi_array)\n",
    "    #print (\"shrinked midi_array.shape: \", midi_array.shape)\n",
    "\n",
    "    # create label arrays\n",
    "    labels_list = midi_to_arrays(midi_array, len(feats_list), feats_list.shape[1])\n",
    "    # return numpy arrays\n",
    "    labels_list = np.array(labels_list, dtype='int64')\n",
    "    \n",
    "    #print (\"labels: \", labels_list.shape)\n",
    "    \n",
    "    return feats_list , labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {dev only}\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "DEV_MODE = True\n",
    "# these values define the resolution of the data\n",
    "SEGMENT_LEN = 0.1 # length of each segment in seconds\n",
    "WINDOW_LEN = 1024\n",
    "HOP_LEN = 280\n",
    "OVERLAP = 0.5\n",
    "\n",
    "if DEV_MODE:\n",
    "    # get complete list of train feats / labels\n",
    "    \n",
    "    dev_csv = []\n",
    "    dev_csv.append(train_csv[1])\n",
    "    dev_csv.append(train_csv[2])\n",
    "    dev_csv.append(train_csv[3])\n",
    "    dev_csv.append(train_csv[4])\n",
    "    \n",
    "    startTime = time.time()\n",
    "    feats_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for i, index in enumerate(tqdm(dev_csv)):\n",
    "        print ('\\n', i, \" file: \", index.audio_filename, \" \", index.duration, \"sec bpm: \", index.bpm)\n",
    "        feats, labels = get_data_segs(index, SEGMENT_LEN, WINDOW_LEN, HOP_LEN, OVERLAP, print_out=True)\n",
    "        print ('feats.shape: ', feats.shape, ' labels.shape: ', labels.shape)\n",
    "        if (feats.shape[0] == labels.shape[0]):\n",
    "            for j in range(len(feats)):\n",
    "                # print (\"\\t\", j, \" feats: \", feats[j].shape, \" labels: \", labels[j].shape)\n",
    "                # show_midi_plot(labels[j])\n",
    "                # show_spectrograph(feats[j])\n",
    "                # show_midi_over_spec(feats[j], labels[j])\n",
    "                # print ('feats: ', feats)\n",
    "                # print ('labels: ', labels)\n",
    "                feats_list.append(feats[j])\n",
    "                labels_list.append(labels[j])\n",
    "    # make into numpy arrays\n",
    "    feats_array = np.array(feats_list, dtype='float64')\n",
    "    labels_array = np.array(labels_list, dtype='int64')\n",
    "    print (\"train_feats.shape: \", feats_array.shape)\n",
    "    print (\"train_labels.shape: \", labels_array.shape)\n",
    "    # dataset complete\n",
    "    print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert midi to array and back to midi for testing\n",
    "\n",
    "from ipynb.fs.full.convert_to_midi import convert_array_to_midi\n",
    "\n",
    "# get correct index\n",
    "train_index = 666\n",
    "data = train_csv[train_index]\n",
    "print (\"data.name: \", data.audio_filename, \" duration: \", data.duration, \" sec\")\n",
    "data_id = '_' + data.audio_filename.split('/')[2]\n",
    "data_id = data_id.split('.')[0]\n",
    "print (\"data_id: \", data_id)\n",
    "\n",
    "# these values define the resolution of the data\n",
    "segment_length = 4.99\n",
    "window_size = 0.025\n",
    "window_stride = 0.01\n",
    "\n",
    "feats_list = []\n",
    "labels_list = []\n",
    "feats, labels = index_to_arrays(data, segment_length, window_size, window_stride)\n",
    "for j in range(len(feats)):\n",
    "        print (\"\\t\", j, \" feats: \", feats[j].shape, \" labels: \", labels[j].shape)\n",
    "        # show_midi_plot(labels[j])\n",
    "        # show_spectrograph(feats[j])\n",
    "        # show_midi_over_spec(feats[j], labels[j])\n",
    "        feats_list.append(feats[j])\n",
    "        labels_list.append(labels[j])\n",
    "# make into numpy arrays\n",
    "feats = np.array(feats_list, dtype='float64')\n",
    "labels = np.array(labels_list, dtype='int64')\n",
    "print (\"feats.shape: \", feats.shape)\n",
    "print (\"labels.shape: \", labels.shape)\n",
    "# create dataset folder if it does not exist\n",
    "if not os.path.exists('data/midi'):\n",
    "        os.mkdir('data/midi')\n",
    "# save to file\n",
    "np.save(\"data/midi/data\" + data_id + \".npy\", labels, allow_pickle=True)\n",
    "\n",
    "# convert back to midi\n",
    "np_array = np.load(\"data/midi/data\" + data_id + \".npy\", allow_pickle=True)\n",
    "np_array = np_array.reshape(np_array.shape[0]*np_array.shape[1], np_array.shape[2])\n",
    "print (\"np array shape: \", np_array.shape)\n",
    "\n",
    "show_midi_plot(np_array)\n",
    "\n",
    "length_seconds = int(np.ceil(segment_length)) * labels.shape[0]\n",
    "midi_file = convert_array_to_midi(np_array, length_seconds)\n",
    "midi_file.save(\"data/midi/midi\" + data_id + \".mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.0 run dataset creation loops - save to file\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# data id (used to make different datasets)\n",
    "data_id = '_32x16'\n",
    "print (\"DATASET ID: \", data_id)\n",
    "\n",
    "# these values define the resolution of the data\n",
    "SEGMENT_LEN = 0.1 # length of each segment in seconds\n",
    "WINDOW_LEN = 1024\n",
    "HOP_LEN = 280\n",
    "OVERLAP = 0.5\n",
    "\n",
    "# reset temp folder\n",
    "reset_temp_folder()\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#           TRAINING DATA               #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# get complete list of train feats / labels\n",
    "print (\"starting training dataset creation...\")\n",
    "startTime = time.time()\n",
    "train_feats = []\n",
    "train_labels = []\n",
    "\n",
    "testy_csv = []\n",
    "testy_csv.append(train_csv[0])\n",
    "testy_csv.append(train_csv[1])\n",
    "testy_csv.append(train_csv[2])\n",
    "testy_csv.append(train_csv[3])\n",
    "\n",
    "for i, index in enumerate(tqdm(train_csv)):\n",
    "    # print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = get_data_segs(index, SEGMENT_LEN, WINDOW_LEN, HOP_LEN, OVERLAP, print_out=False)\n",
    "    if (feats.shape[0] == labels.shape[0]):\n",
    "        for j in range(len(feats)):\n",
    "            # print (\"\\t\", j, \" feats: \", feats[j].shape, \" labels: \", labels[j].shape)\n",
    "            # show_midi_plot(labels[j])\n",
    "            # show_spectrograph(feats[j])\n",
    "            # show_midi_over_spec(feats[j], labels[j])\n",
    "            train_feats.append(feats[j])\n",
    "            train_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "train_feats = np.array(train_feats, dtype='float32')\n",
    "train_labels = np.array(train_labels, dtype='int32')\n",
    "print (\"train_feats.shape: \", train_feats.shape)\n",
    "print (\"train_labels.shape: \", train_labels.shape)\n",
    "# dataset complete\n",
    "print (\"training dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# create dataset folder if it does not exist\n",
    "if not os.path.exists('data/dataset' + data_id):\n",
    "        os.mkdir('data/dataset' + data_id)\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"train_feats\" + data_id + \".npy\", train_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"train_labels\" + data_id + \".npy\", train_labels, allow_pickle=True)\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#               TEST DATA               #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# get complete list of test feats / labels\n",
    "print (\"starting test dataset creation...\")\n",
    "startTime = time.time()\n",
    "test_feats = []\n",
    "test_labels = []\n",
    "for i, index in enumerate(tqdm(test_csv)):\n",
    "    #print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = get_data_segs(index, SEGMENT_LEN, WINDOW_LEN, HOP_LEN, OVERLAP, print_out=False)\n",
    "    if (feats.shape[0] == labels.shape[0]):\n",
    "        for j in range(len(feats)):\n",
    "            # show_midi_over_spec(feats[j], labels[j])\n",
    "            test_feats.append(feats[j])\n",
    "            test_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "test_feats = np.array(test_feats, dtype='float32')\n",
    "test_labels = np.array(test_labels, dtype='int32')\n",
    "print (\"test_feats.shape: \", test_feats.shape)\n",
    "print (\"test_labels.shape: \", test_labels.shape)\n",
    "# dataset complete\n",
    "print (\"test dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"test_feats\" + data_id + \".npy\", test_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"test_labels\" + data_id + \".npy\", test_labels, allow_pickle=True)\n",
    "\n",
    "#########################################\n",
    "#                                       #\n",
    "#           VALIDATION DATA             #\n",
    "#                                       #\n",
    "#########################################\n",
    "\n",
    "# # get complete list of validation feats / labels\n",
    "print (\"starting validation dataset creation...\")\n",
    "startTime = time.time()\n",
    "val_feats = []\n",
    "val_labels = []\n",
    "for i, index in enumerate(tqdm(validation_csv)):\n",
    "    #print (i, \" file: \", index.audio_filename, \" \", index.duration, \" sec\")\n",
    "    feats, labels = get_data_segs(index, SEGMENT_LEN, WINDOW_LEN, HOP_LEN, OVERLAP, print_out=False)\n",
    "    if (feats.shape[0] == labels.shape[0]):\n",
    "        for j in range(len(feats)):\n",
    "            # show_midi_over_spec(feats[j], labels[j])\n",
    "            val_feats.append(feats[j])\n",
    "            val_labels.append(labels[j])\n",
    "# make into numpy arrays\n",
    "val_feats = np.array(val_feats, dtype='float32')\n",
    "val_labels = np.array(val_labels, dtype='int32')\n",
    "print (\"val_feats.shape: \", val_feats.shape)\n",
    "print (\"val_labels.shape: \", val_labels.shape)\n",
    "# dataset complete\n",
    "print (\"validation dataset complete!\")\n",
    "print (\"time elapsed: \", round((time.time() - startTime), 2), \" sec\\n\")\n",
    "# save feats / labels lists to file\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"val_feats\" + data_id + \".npy\", val_feats, allow_pickle=True)\n",
    "np.save(\"data/dataset\" + data_id + \"/\" + \"val_labels\" + data_id + \".npy\", val_labels, allow_pickle=True)\n",
    "\n",
    "# reset temp folder\n",
    "reset_temp_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af153e239d61b5c0d363f35fe8a0509d492506f382d017c98fa3fb49fce70a72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
